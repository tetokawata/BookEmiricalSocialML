# セミパラメトリック推定によるパラメタ推定 {#sec-CausalMachine}

-   @chernozhukov2018 を実装する

## 設定

::: {.panel-tabset}

### R

```{r SetUpR}
library(tidyverse)
library(recipes)
library(mlr3verse)
library(mlr3pipelines)
library(data.table)
library(DoubleML)

Data_R <- fread("ExampleData/Example.csv")

Task_R <- double_ml_data_from_data_frame(Data_R,
                                         x_cols = c("TradeQ", "Size", "BuildYear", "Distance"),
                                         y_col = c("Price"),
                                         d_cols = c("Reform"))
```

### Python

```{python SetUpPython}
import pandas as pd
from sklearn.base import clone
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import RandomForestClassifier
from doubleml import DoubleMLData
from doubleml import DoubleMLPLR
from doubleml import DoubleMLIRM

Data_Python = pd.read_csv('ExampleData/Example.csv')

Task_Python = DoubleMLData(Data_Python, 
                          y_col = 'Price',
                          d_cols = 'Reform',
                          x_cols = ['TradeQ',"Size","Distance","BuildYear"])
```


:::

## 平均効果の推定: Partial Linear Model

- 部分線形モデル [@robinson1988]

- RandomForestとOLSのStackingを用いる

    - Pythonについて、現状、RandomForestのみ

::: {.panel-tabset}

### R

```{r PLRegressR}
RegOLS <- lrn("regr.lm",
  id = "RegressionOLS"
)

RegRF <- lrn("regr.ranger",
  id = "RegressionRandomForest"
)

RegLearners <- list(
  RegOLS,
  RegRF
)

RegSuperLearner <- lrn("regr.lm",
                    id = "RegressionSuperLearner")

RegNuisanceLearner <- 
  pipeline_stacking(RegLearners, RegSuperLearner) |> 
  as_learner()

lgr::get_logger("mlr3")$set_threshold("warn")

FitPLR_R <- DoubleMLPLR$new(Task_R,
                            ml_l=RegNuisanceLearner$clone(), 
                            ml_m=RegNuisanceLearner$clone(),
                            n_folds = 2)

FitPLR_R$fit()

print(FitPLR_R)
```

### Python

```{python PLRegressPython}
FitPLR_Python = DoubleMLPLR(Task_Python,
                            RandomForestRegressor(n_estimators = 500),
                            RandomForestRegressor(n_estimators = 500),
                            n_folds = 2)

FitPLR_Python.fit()

print(FitPLR_Python)
```

:::

## 平均効果の推定: AIPW

-   AIPW [@robins1995]

::: {.panel-tabset}

### R

```{r AIPWeightR}
ProbOLS <- lrn("classif.log_reg",
  id = "ProbLM",
  predict_type = "prob"
)

ProbRF <- lrn("classif.ranger",
  id = "ProbRanger",
  predict_type = "prob"
)

ProbLearners <- list(ProbOLS,ProbRF)

ProbSuperLearner <- lrn("classif.log_reg",
                    id = "ProbSuperLearner")

ProbNuisanceLearner <- pipeline_stacking(ProbLearners, ProbSuperLearner) |> 
  as_learner()

lgr::get_logger("mlr3")$set_threshold("warn")

FitAIPW_R = DoubleMLIRM$new(Task_R,
                            ml_g=RegNuisanceLearner, 
                            ml_m=ProbNuisanceLearner,
                            n_folds = 2,
                            trimming_threshold = 0.1)

FitAIPW_R$fit()

print(FitAIPW_R)
```

### Python

```{python AIPWeightPython}
FitAIPW_Python = DoubleMLIRM(Task_Python,
                            RandomForestRegressor(n_estimators = 500),
                            RandomForestClassifier(n_estimators = 500),
                            n_folds = 2,
                            trimming_threshold = 0.1)
  
FitAIPW_Python.fit()

FitAIPW_Python.summary
```

:::
