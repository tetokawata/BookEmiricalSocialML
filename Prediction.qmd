# 予測 {#sec-Prediction}

- 手持ちのデータと同じ母集団から新しくランダムサンプリングされ、$X$のみが観察できるサンプルについて$Y$の値を予測する。

  - データ分割を用いたモデル選択、評価を行う

## 問題設定

- 事前に定義する損失関数の母平均 (Population Risk) を最小化するような、予測関数$f(X)$の推定を目指す。

  - 以下ではMean squared error(MSE)を損失関数として用いる。確率変数$Y,X$について予測問題は以下のように定義できる

$$\min_{f(X)}MSE = \int_{x}E[(Y_i-f(x))^2|X_i=x]g(x)dx$$

- $g(x)$ は$x$の分布関数

  - 一般に以下の最適化問題の解と一致

$$\min_{f(X_i)} \int_{x}E[(\mu(x)-f(x))^2|X_i=x]g(x)dx$$

ただし $\mu(x)=E[Y_i|X_i=x]$

- 上記問題を具体的に解くアルゴリズムとして、ここでは OLS, LASSO, Random Forest、およびそれらのSuperLearnerを実装する。

## 実装

- 以下のPipelineを実装

```{mermaid}
flowchart TB
  A[データとパッケージの読み込み] --> B[予測タスクの定義/サンプル分割]
  B --> C1[BuildIn 推定アルゴリズムの定義]
  B --> C2[+ 前処理]
  B --> C3[+ パラメータTuning]
  C1 --> C4[Super Learnerの定義]
  C2 --> C4[Super Learnerの定義]
  C3 --> C4[Super Learnerの定義]
  C1 --> D[Trainデータのみを用いたベンチマーク]
  C2 --> D[Trainデータのみを用いたベンチマーク]
  C3 --> D[Trainデータのみを用いたベンチマーク]
  C4 --> D[Trainデータのみを用いたベンチマーク]
  D --> E[最善の予測モデルを用いた最終推計]
  E --> F[Testデータによる評価]
```


### パッケージ & データ

- ここではpipelinesによるデータ整備は行わない (暫定的)

- 追加でlgr (表示するメッセージを操作), future (並列計算)  パッケージを使用

```{r SetUpR}
library(tidyverse)
library(mlr3verse) # 機械学習のメタパッケージ
library(mlr3pipelines) # Stacking用

Raw <- read_csv("ExampleData/Example.csv")

set.seed(123)
```

### 推定タスクの定義

- 分割数、繰り返し計算回数は最小限に設定

    - 実戦では増やす

```{r DefineR}
Task <- as_task_regr(Raw, target = "Price") # Task設定

Group <- partition(Task, ratio = 0.8) # Train/Test分割

R2 <-  msr("regr.rsq") # R2で評価

CV <- rsmp("cv",folds = 2) # 2分割交差検証

Terminal = trm("evals",
               n_evals = 20) # 20回の繰り返し評価

Tuner <- tnr("grid_search",
             resolution = 20) # 20回のグリッドサーチ
```


### 使用するBuildIn Algorithmを定義

```{r Learner$}
SimpleOLS <- lrn("regr.lm", id = "SimpleOLS") # OLS

RandomForest <- lrn("regr.ranger", id = "RandomForest") # RandomForest
```

### PreProcess

- 線形モデルについて、連続変数二乗項と交差項を導入

    - [Duflo](https://github.com/demirermert/MLInference/blob/master/NBER_SI_DEV_master_lecture.pdf) のおすすめ

```{r WithPreProcessR}
Mutate = po("mutate") # データ加工
Mutate$param_set$values$mutation = list(
  Size2 = ~ Size*Size,
  TradeQ2 = ~ TradeQ*TradeQ,
  BuildYear2 = ~BuildYear*BuildYear,
  Distance2 = ~Distance*Distance,
  Size_TradeQ = ~Size*TradeQ,
  Size_BuildYear = ~Size*BuildYear,
  Size_Distance = ~ Size*Distance,
  TradeQ_BuildYear = ~TradeQ*BuildYear,
  TradeQ_Distance = ~TradeQ*Distance,
  BuildYear_Distance = ~BuildYear*Distance
) # 二乗項と交差項の作成

Scale = po("scale") # 標準化

OLS <- Mutate %>>% 
  Scale %>>% 
  lrn("regr.lm") |> 
  as_learner() # 二乗項と交差項を導入したOLS

OLS$id <- "OLS"
```

### チューニング付き推定方法の定義

- Tree、LASSO アルゴリズムについて、HyperParameterを交差検証により推定する

- 探索するHyperParameterの範囲を設定する必要がある

    - [mlr3tuningspaces](https://github.com/mlr-org/mlr3tuningspaces)パッケージが提供するおすすめ範囲を使用

```{r TunedLearnerR}
Tree <- lrn("regr.rpart") |> 
  lts()

Tree <- AutoTuner$new(
  learner = Tree,
  resampling = CV,
  measure = R2,
  terminator = Terminal,
  tuner = Tuner
  )

Tree$id <- "Tree"

LASSO <- lrn("regr.glmnet") |> 
  lts()

LASSO <- Mutate %>>% 
  Scale %>>% 
  LASSO |> 
  as_learner()

LASSO <- AutoTuner$new(
  learner = LASSO,
  resampling = CV,
  measure = R2,
  terminator = Terminal,
  tuner = Tuner
  )

LASSO$id <- "LASSO"
```

### SuperLearnerの定義

```{r StackR}
BaseLearner <- list(
  OLS,
  SimpleOLS,
  RandomForest,
  Tree,
  LASSO
) # 個別推定アルゴリズム

SuperLearner <- lrn("regr.lm",
                    id = "SuperLearner") # 個別予測をまとめるアルゴリズム

Stacking <- pipeline_stacking(BaseLearner, SuperLearner) |> 
  as_learner() # SuperLearnerの定義

Stacking$id <- "Stacking"
```

### ベンチマーク・テスト

```{r}
Design <- benchmark_grid(
  tasks = list(Task$clone()$filter(Group$train)),
  learners = list(
    OLS,
    SimpleOLS,
    LASSO,
    RandomForest,
    Tree,
    Stacking
  ),
  resamplings = CV
)

lgr::get_logger("mlr3")$set_threshold("error") # Errorのみを表示
lgr::get_logger("bbotk")$set_threshold("error") # Errorのみを表示
future::plan("multisession") # 並列処理

BenchMark <- benchmark(Design)

BenchMark$aggregate(R2)
```

- RandomForestとStackingはComparableな性能

    - とりあえずStackingを採用
    
### 最終モデル

- Stakingを全TrainingDataで推定

- TestDataで評価

```{r}
SuperLearner$train(Task, row_ids = Group$train)

SuperLearner$predict(Task, Group$test)$score(R2)
```
