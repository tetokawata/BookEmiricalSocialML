# 教師付き学習による母平均モデルの推定 {#sec-Prediction}

- 手持ちのデータと同じ母集団から新しくランダムサンプリングされ、$X$のみが観察できるサンプルについて$Y$の値を予測する。

  - データ分割を用いたモデル選択、評価を行う

## 問題設定

- 母平均関数 $E[Y|X]$ を近似する関数 $f(X)$ の推定をする。具体的には、母集団上での二乗誤差最小化を目指す。

$$\min_{f(X)} E[(E[Y|X]-f(X))^2]$$

- 上記の最適化問題の解を近似する関数 $f(X)$ は、標準的な予測問題において極めて有益である。

- 上記問題を具体的に解くアルゴリズムとして、ここでは OLS, ElasticNet, Random Forest、およびそれらのStacking (SuperLearner) を実装する。


### 予測問題

- 事前に定義する損失関数の母平均 (Population Risk) を最小化するような、予測関数$f(X)$の推定を目指す。

  - 以下ではMean squared error(MSE)を損失関数として用いる。確率変数$Y,X$について予測問題は以下のように定義できる

$$\min_{f(X)}MSE = \int_{x}E[(Y-f(x))^2|X_i=x]\times g(x)dx$$

- $g(x)$ は$x$の分布関数

  - 一般に以下の最適化問題の解と一致

$$\min_{f(X_i)} \int_{x}E[(E[Y|X]-f(x))^2|X_i=x]g(x)dx$$

- 理想の予測モデルは、 $f(X)=E[Y|X]$

    - $E[Y|X]$ を十分に近似する関数を推定できれば、最善に近い予測性能を期待できる
    

## 実装

::: {.panel-tabset}

### R

- 以下のPipelineを実装

```{mermaid}
flowchart TB
  A[データとパッケージの読み込み] --> B[予測タスクの定義/サンプル分割]
  B --> C1[BuildIn 推定アルゴリズムの定義]
  B --> C2[+ 前処理]
  B --> C3[+ パラメータTuning]
  C1 --> C4[Super Learnerの定義]
  C2 --> C4[Super Learnerの定義]
  C3 --> C4[Super Learnerの定義]
  C1 --> D[Trainデータのみを用いたベンチマーク]
  C2 --> D[Trainデータのみを用いたベンチマーク]
  C3 --> D[Trainデータのみを用いたベンチマーク]
  C4 --> D[Trainデータのみを用いたベンチマーク]
  D --> E[最善の予測モデルを用いた最終推計]
  E --> F[Testデータによる評価]
```


#### パッケージ & データ

- ここではpipelinesによるデータ整備は行わない (暫定的)

- 追加でlgr (表示するメッセージを操作), future (並列計算)  パッケージを使用

```{r SetUpR}
library(tidyverse)
library(mlr3verse) # <1>
library(mlr3pipelines) # <2>

Raw <- read_csv("ExampleData/Example.csv")

set.seed(123)
```

1. 教師付き学習のメタパッケージ

2. Stacking用

#### 推定タスクの定義

- 分割数、繰り返し計算回数は最小限に設定

    - 実戦では増やす

```{r DefineR}
Task <- as_task_regr(
  Raw, 
  target = "Price",
  id = "Price") # <1>

R2 <-  msr("regr.rsq") # <2>

CV <- rsmp("cv",folds = 2) # <3>

Terminal = trm(
  "evals",
  n_evals = 20) # <4>

Tuner <- tnr("random_search") # <5>
```

1. 推定に用いるデータと結果変数を指定

2. R2を評価指標に使用

3. 2分割交差検証を指定

4. 20個のパラメタセットを検証

5. ランダムサーチで検証するパラメタセットを選ぶ

#### 使用するBuildIn Algorithmを定義

```{r Learner$}
SimpleOLS <- lrn( # <1>
  "regr.lm", # <1>
  id = "SimpleOLS" # <1>
  ) # <1>

RandomForest <- lrn( # <2>
  "regr.ranger", # <2>
  id = "RandomForest" # <2>
  ) # <2>
```

1. 単純なOLS

2. RandomForest

#### PreProcess

- 線形モデルについて、連続変数二乗項と交差項を導入

    - [Duflo](https://github.com/demirermert/MLInference/blob/master/NBER_SI_DEV_master_lecture.pdf) のおすすめ

```{r WithPreProcessR}
Mutate = po("mutate") # <1>

Mutate$param_set$values$mutation = list( # <2>
  Size2 = ~ Size*Size, # <2>
  TradeQ2 = ~ TradeQ*TradeQ, # <2>
  BuildYear2 = ~BuildYear*BuildYear, # <2>
  Distance2 = ~Distance*Distance, # <2>
  Size_TradeQ = ~Size*TradeQ, # <2>
  Size_BuildYear = ~Size*BuildYear, # <2>
  Size_Distance = ~ Size*Distance, # <2>
  TradeQ_BuildYear = ~TradeQ*BuildYear, # <2>
  TradeQ_Distance = ~TradeQ*Distance, # <2>
  BuildYear_Distance = ~BuildYear*Distance # <2>
  )  # <2>

Scale = po("scale") # <3>

OLS <- Mutate %>>% # <4>
  Scale %>>% # <4>
  lrn("regr.lm") |> # <4>
  as_learner() # <4>

OLS$id <- "OLS" # <4>
```

1. $X$ の加工

2. 二乗項と交差項を作成

3. 標準化(平均を引き、標準偏差で叙す)

4. OLSと結合

#### チューニング付き推定方法の定義

- Tree、ElasticNet (LASSO/Ridge) アルゴリズムについて、HyperParameterを交差検証により推定する

- 探索するHyperParameterの範囲を設定する必要がある

    - [mlr3tuningspaces](https://github.com/mlr-org/mlr3tuningspaces)パッケージが提供するおすすめ範囲を使用

```{r TunedLearnerR}
Tree <- lrn("regr.rpart") |> 
  lts() # <1>

Tree <- AutoTuner$new( # <2>
  learner = Tree, # <2>
  resampling = CV, # <2>
  measure = R2, # <2>
  terminator = Terminal, # <2>
  tuner = Tuner # <2>
  ) # <2>

Tree$id <- "Tree" # <3>

RegulizedLinear <- lrn("regr.glmnet") |> 
  lts() # <4>

RegulizedLinear <- Mutate %>>% 
  Scale %>>% 
  RegulizedLinear |> 
  as_learner() # <5>

RegulizedLinear <- AutoTuner$new( # <6>
  learner = RegulizedLinear, # <6>
  resampling = CV, # <6>
  measure = R2, # <6>
  terminator = Terminal, # <6>
  tuner = Tuner # <6>
  ) # <6>

RegulizedLinear$id <- "ElasticNet" # <7>
```

1. TuningSpaceを指定したTreeを定義

2. HyperParameter Tuningを指定

3. Treeと名づける

4. TuningSpaceを指定したElasticNetを定義

5. 二乗項/交差項作成を付与

6. HyperParameter Tuningを指定

7. ElasticNetと名づける

#### SuperLearnerの定義

```{r StackR}
BaseLearner <- list( # <1>
  OLS, # <1>
  RandomForest, # <1>
  Tree, # <1>
  RegulizedLinear # <1>
  ) # <1>

SuperLearner <- lrn( # <2>
  "regr.lm", # <2>
  id = "SuperLearner") # <2>

Stacking <- pipeline_stacking( # <3>
  BaseLearner,  # <3>
  SuperLearner, # <3>
  use_features = FALSE) |>  # <3>
  as_learner() # <3>

Stacking$id <- "Stacking" # <4>
```

1. 個別のアルゴリズムの指定

2. 集計用アルゴリズムの指定

3. Stackingの定義

4. Stackingと名づけ

#### 交差推定による評価

```{r}
Design <- benchmark_grid( # <1>
  tasks = Task, # <2>
  learners = list( # <3>
    OLS, # <3>
    SimpleOLS, # <3>
    RegulizedLinear, # <3>
    RandomForest, # <3>
    Tree, # <3>
    Stacking # <3>
  ), # <3>
  resamplings = CV # <4>
  )

lgr::get_logger("mlr3")$set_threshold("error") # <5>
lgr::get_logger("bbotk")$set_threshold("error") # <5>
future::plan("multisession") # <6>

BenchMark <- benchmark(Design) # <7>

BenchMark$aggregate(R2) # <8>
```

1. 評価の枠組みを定義

2. 評価対象のタスク (データと結果変数) を定義

3. 評価対象のアルゴリズムを定義

4. 評価方法 (交差検証) を定義

5. Errorメッセージのみ表示

6. 並列処理を指定

7. 評価を実行

8. R2を計算

- RandomForestとStackingはComparableな性能


### Python

- OLSとRandom Forestで予測モデルを推定し、交差検証で比較する。

#### パッケージ & データ

```{python}
from sklearn import linear_model
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
import pandas as pd
import numpy as np

data = pd.read_csv("ExampleData/Example.csv")

np.random.seed(123) # Fix seed

Y = data['Price']

X = data.drop(
  'Price',
  axis = 1)
```

#### 使用するアルゴリズム

```{python}
OLS = linear_model.LinearRegression() # OLS

RF = RandomForestRegressor(
  n_estimators = 500) # Random Forest
```

#### 交差推定によるテスト

```{python}
Folds = KFold(n_splits=5, shuffle = True) # サンプル5分割
```

- OLS のテスト

```{python}
np.mean(cross_val_score(OLS, X, Y, cv = Folds))
```

- Random Forestのテスト

```{python}
np.mean(cross_val_score(RF, X, Y, cv = Folds))
```


:::