# 線形モデルによるパラメータの推定 {#sec-ParameterLinearEstimation}

-   関心のあるパラメータ$\tau(X)=E[Y|d,X]-E[Y|d',X]$を埋め込んだ線形モデルを推定する。

    -   典型的には、$E[Y|D,X]$を線形近似し、推定する。

$$E[Y|D=d,X=x]=\underbrace{\tau}_{Interest\ parameter}\times d+\underbrace{f(x)}_{Nuisance\ function}$$ - $f(X)=\beta_0 + \beta_1 X_1 + ...+\beta_LX_L$

-   $\tau$について点推定だけでなく、信頼区間も推定する。

    -   [Section -@sec-ParameterEstimation] 線形モデルを推定し、信頼区間を計算する方法を紹介

    -   [Section -@sec-Matching] 近似モデルの定式化への依存度を下げるために、マッチング法を用いた前処理を導入

    -   [Section -@sec-Appendix]推定結果の表によるまとめ、可視化、および複数の推定結果を効率的に保存する方法を紹介

## パッケージ & データ

```{r}
#| message: false
#| warning: false
library(tidyverse)
library(AER)
library(estimatr)
library(MatchIt)

data("CPSSW9204")
```

## パラメータの推定 {#sec-ParameterEstimation}

-   $\tau(x)=\tau,f(x)=\beta_0+\beta_1x_1+...+\beta_Lx_L$と特定化

-   サンプル内MSEを最大化するように推定

-   robust standard errorを計算するためにestimatrパッケージ[@R-estimatr]を利用

-   lm_robust関数で推定

```{r}
lm_robust(earnings ~ degree + gender + age + year, # Outcome ~ Treatment + Controls
          data = CPSSW9204)
```

-   線形モデルによる推定は、いくつかの問題がある

    -   異なるグループ間で、$X$の分布が異なる場合、回帰式の定式化に強く依存する

    -   一般に平均効果ではなく、加重平均が推計される

    -   サンプルサイズに比べて、少数のコントロール変数を導入できない

-   以下ではマッチング法、機械学手法を用いた頑強な推定を目指す

### RCTデータへの応用

-   原因変数が完全にランダム化されている場合、因果効果の**識別**を目的に回帰分析を応用する必要はない

-   因果効果の**推定**の改善、効率性向上、を目的として線形モデルの利用は議論されてきた。

-   @lin2013 は、以下のような交差項を導入したモデルを用いることで、平均の差の推定に比べて、漸近的効率性が悪化することはない（同等か改善する）ことを示した

$$E[Y|D,X]=\beta_{D}\times D+\beta_1\times X_1+...+\beta_L\times X_L$$

$$+\underbrace{\beta_{1D}\times D\times X_1+...+\beta_{LD}\times D\times X_L}_{交差項}$$

-   lm_lin関数で推定可能

```{r}
lm_lin(earnings ~ degree, # Outcome ~ Treatment
       ~ gender + age + year, # ~ Controls
       data = CPSSW9204)
```

## マッチング法による修正 {#sec-Matching}

-   回帰を行う事前準備としてマッチング法を利用する

    -   重回帰が持つ関数形への依存度を減らせる [@ho2007matching]

    -   MathItパッケージ [@MatchIt2011]を利用

-   多数のマッチング法が実装されている

### Exact matching

-   Coarsened exact matching[@iacus2012causal]の実装

    -   連続変数をカテゴリー変数化することで、マッチングできるサンプルサイズを増やすことが期待できる

```{r}
fit.m <- matchit(degree ~ gender + age + year,
                 data = CPSSW9204,
                 method = "CEM"
                 )
```

-   マッチング結果の表示

```{r}
fit.m
```

-   Sample sizesにて、マッチングできなかったサンプル数（985のコントロールグループ中、667サンプルがマッチングできなかった）が確認できる

-   マッチング結果の図示

```{r}
fit.m |> 
  summary() |> 
  plot(abs = FALSE)
```

-   マッチング結果を変数として含んだデータを作成

```{r}
df <- match.data(fit.m)
```

-   "subclass": マッチングしたグループ

-   "weights"：マッチング後の推計に用いるウェイト

-   マッチングしたデータを用いた推定

    -   新たに作成されるweight (defaltではweights)を用いた、加重推定で実装

```{r}
lm_robust(earnings ~ degree + gender + age + year,
          df,
          weights = weights,
          clusters = subclass)
```

### Propensity score with subclassification

-   Coarsened exact matchingでもマッチングできないサンプルが多数出てくる可能性

    -   とくに$X$が大量にある場合

-   1次元の距離指標を用いて、マッチングを行う

    -   距離指標としては、Mahalanobis' Distance、Propensity scoreなど

-   ここではPropensity score $p_d(X)$を用いる

$$p_d(X)\equiv \Pr[D=d|X]$$

-   属性$X$のユニットの中で、原因変数の値が$d$である人の割合

-   未知の場合、データから推定する必要がある

-   推定された傾向スコアを用いたStratification マッチング

    -　ロジットにて傾向スコアを推定

```{r}
fit.m <- matchit(degree ~ gender + age + year,
                 data = CPSSW9204,
                 method = "subclass",
                 estimand = "ATE"
                 )
```

-   マッチング結果

```{r}
summary(fit.m)
```

-   マッチング結果の図示

```{r}
fit.m |> 
  summary() |> 
  plot(abs = FALSE)
```

-   マッチングしたデータを用いた推定

```{r}
lm_robust(earnings ~ degree + gender + age + year,
          df,
          weights = weights,
          clusters = subclass)
```

## 付録：推定結果の保存と表示 {#sec-Appendix}

### Dot-and-Whisker plotによる可視化

-   Dot-and-Whisker図により点推定量と信頼区間を可視化

```{r}
fit.m <- matchit(degree ~ gender + age + year,
                 data = CPSSW9204,
                 method = "CEM"
                 )

df <- match.data(fit.m)

Result1 <- lm_robust(earnings ~ degree + gender + age + year,
            data = df) |> 
  tidy() |> 
  filter(term == "degreebachelor"
         ) |> 
  mutate(Method = "OLS")

Result1 |> 
  ggplot(aes(y = term,
             x = estimate,
             xmin = conf.low,
             xmax = conf.high)
         ) +
  geom_pointrange() +
  geom_vline(xintercept = 0) +
  theme_bw()
```

```{r}
Result2 <- lm_robust(earnings ~ degree + gender + age,
            data = df,
            weights = weights,
            clusters = subclass) |> 
  tidy() |> 
  filter(term == "degreebachelor"
         ) |> 
  mutate(Method = "Matching + OLS")

Result1 |> 
  bind_rows(Result2) |> 
  ggplot(aes(y = Method,
             x = estimate,
             xmin = conf.low,
             xmax = conf.high)
         ) +
  geom_pointrange() +
  geom_vline(xintercept = 0) +
  theme_bw()
```
