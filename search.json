[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Rによる比較・因果推論・予測研究 (ver 0.01)",
    "section": "",
    "text": "定量的な比較、（反実仮想）因果推定、予測分析をRによって行う方法を紹介\n経済学におけるデータ分析の大部分は、複数の変数間での関係性の理解・利用を目的としている。 本ページでは、ある結果変数\\(Y\\)と独立変数（群）\\(X=X_1,...,X_L\\)の関係性に焦点を当てる。 また\\(Y\\)と\\(X\\)がともに観察でき、関心のある母集団からランダムサンプリングされたデータが入手出来ている。\n具体的な分析目標を大きく（予測）\\(Y\\)の予測関数の推定、（比較）異なる\\(X\\)間での\\(Y\\)の比較、（因果効果）\\(X\\)の変化が\\(Y\\)に与える因果効果の推定、に大別し、それぞれについて簡単な説明とRのサンプルコードの提供\nデータインポート、整理、可視化を行う関数群を統合的に提供するtidyverseパッケージの利用\nExample dataとしては、AERパッケージに含まれるNMES1988(the US National Medical Expenditure Survey)を利用\nSection 2 線形モデルを用いたパラメータ推定\nSection 3 予測モデル推定\nSection 4 セミパラメトリック推定 \\(+\\) 機械学習 による平均差の推定\nSection 5 Treatmentグループ別の記述統計\nSection 6 recipesパッケージを用いた統合的なデータ整備"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  準備",
    "section": "",
    "text": "本ページでは、tidyverseパッケージの利用を前提とし、pipe演算子を用いたコード例を示す"
  },
  {
    "objectID": "intro.html#tidyverse",
    "href": "intro.html#tidyverse",
    "title": "1  準備",
    "section": "1.1 tidyverse",
    "text": "1.1 tidyverse\n\nデータ整備・可視化等の関数群を提供する（メタ）パッケージ\n\n公式ページ"
  },
  {
    "objectID": "intro.html#nativeなpipe演算子",
    "href": "intro.html#nativeなpipe演算子",
    "title": "1  準備",
    "section": "1.2 nativeなpipe演算子",
    "text": "1.2 nativeなpipe演算子\n\nR version 4.1からpipe演算子が、追加パッケージなしで利用可能になった\n\nTools -> Global option -> Code -> “Use native pipe operator” をチェックする\nCtr + Shift + mがショートカット\n現状、magrittrパッケージが提供するpipe (%>%)に比べて、機能が限定されている\n\npipe演算子：二つの入力X1,X2から出力Yを得る関数fについて、pipe演算子を用いると、Y <- X1 |> f(X2)と書き換えられる\npipe演算子を使わない場合、ある出力結果を入力として用いるためには、複数のobjectを作成する必要があり煩雑\n\n\nn <- rnorm(100) # 標準正規分布から100個値を取得し、nと名付ける\n\nhist(n)　# nを用いてヒストグラムを描画\n\n\n\n\n\npipe演算子を使うと以下のようになる\n\n\nrnorm(100) |> \n  hist()"
  },
  {
    "objectID": "ParameterEstimation.html",
    "href": "ParameterEstimation.html",
    "title": "2  線形モデルによるパラメータの推定",
    "section": "",
    "text": "関心のあるパラメータ\\(\\tau(X)=E[Y|d,X]-E[Y|d',X]\\)を埋め込んだ線形モデルを推定する。\n\n典型的には、\\(E[Y|D,X]\\)を線形近似し、推定する。\n\\[E[Y|D=d,X=x]=\\underbrace{\\tau}_{Interest\\ parameter}\\times d+\\underbrace{f(x)}_{Nuisance\\ function}\\] - \\(f(X)=\\beta_0 + \\beta_1 X_1 + ...+\\beta_LX_L\\)"
  },
  {
    "objectID": "ParameterEstimation.html#パッケージ-データ",
    "href": "ParameterEstimation.html#パッケージ-データ",
    "title": "2  線形モデルによるパラメータの推定",
    "section": "2.1 パッケージ & データ",
    "text": "2.1 パッケージ & データ\n\nlibrary(tidyverse)\nlibrary(AER)\nlibrary(estimatr) # Estimation with robust standard error\nlibrary(MatchIt) # Matching for preprocess\n\ndata(\"CPSSW9204\")\n\n\nestimatr\nMatchIt"
  },
  {
    "objectID": "ParameterEstimation.html#sec-ParameterEstimation",
    "href": "ParameterEstimation.html#sec-ParameterEstimation",
    "title": "2  線形モデルによるパラメータの推定",
    "section": "2.2 パラメータの推定",
    "text": "2.2 パラメータの推定\n\n\\(\\tau(x)=\\tau,f(x)=\\beta_0+\\beta_1x_1+...+\\beta_Lx_L\\)と特定化\nサンプル内MSEを最大化するように推定\nrobust standard errorを計算するためにestimatrパッケージを利用\nlm_robust関数で推定\n\n\nlm_robust(earnings ~ degree + gender + age + year, # Outcome ~ Treatment + Controls\n          data = CPSSW9204)\n\n                 Estimate Std. Error    t value      Pr(>|t|)   CI Lower\n(Intercept)    -1.3734240 0.56012981  -2.451974  1.421837e-02 -2.4713435\ndegreebachelor  5.6693812 0.11409767  49.688844  0.000000e+00  5.4457365\ngenderfemale   -2.5584302 0.10555849 -24.237085 2.042463e-127 -2.7653371\nage             0.3999398 0.01870067  21.386388 4.880841e-100  0.3632843\nyear2004        4.7218644 0.10448036  45.193798  0.000000e+00  4.5170708\n                 CI Upper    DF\n(Intercept)    -0.2755044 15583\ndegreebachelor  5.8930259 15583\ngenderfemale   -2.3515232 15583\nage             0.4365953 15583\nyear2004        4.9266581 15583\n\n\n\n線形モデルによる推定は、いくつかの問題がある\n\n異なるグループ間で、\\(X\\)の分布が異なる場合、回帰式の定式化に強く依存する\n一般に平均効果ではなく、加重平均が推計される\nサンプルサイズに比べて、少数のコントロール変数を導入できない\n\n以下ではマッチング法、機械学手法を用いた頑強な推定を目指す\n\n\n2.2.1 RCTデータへの応用\n\n原因変数が完全にランダム化されている場合、因果効果の識別を目的に回帰分析を応用する必要はない\n因果効果の推定の改善、効率性向上、を目的とした線形モデルの利用は議論されてきた\nLin (2013) は、以下のような交差項を導入したモデルを用いることで、平均の差の推定に比べて、漸近的効率性が悪化することはない（同等か改善する）ことを示した\n\n\\[E[Y|D,X]=\\beta_{D}\\times D+\\beta_1\\times X_1+...+\\beta_L\\times X_L\\]\n\\[+\\underbrace{\\beta_{1D}\\times D\\times X_1+...+\\beta_{LD}\\times D\\times X_L}_{交差項}\\]\n\nlm_lin関数で推定可能\n\n\nlm_lin(earnings ~ degree, # Outcome ~ Treatment\n       ~ gender + age + year, # ~ Controls\n       data = CPSSW9204)\n\n                                Estimate Std. Error     t value      Pr(>|t|)\n(Intercept)                   11.8445518 0.05886786 201.2057631  0.000000e+00\ndegreebachelor                 5.6534529 0.11317582  49.9528355  0.000000e+00\ngenderfemale_c                -2.5004885 0.11301520 -22.1252401 7.932323e-107\nage_c                          0.2554277 0.02057814  12.4125730  3.276989e-35\nyear2004_c                     3.7186028 0.11834727  31.4211113 3.546993e-210\ndegreebachelor:genderfemale_c -0.1059052 0.22219513  -0.4766317  6.336311e-01\ndegreebachelor:age_c           0.3271382 0.03945813   8.2907675  1.216210e-16\ndegreebachelor:year2004_c      2.3273241 0.22003125  10.5772436  4.657042e-26\n                                CI Lower   CI Upper    DF\n(Intercept)                   11.7291640 11.9599396 15580\ndegreebachelor                 5.4316151  5.8752907 15580\ngenderfemale_c                -2.7220114 -2.2789655 15580\nage_c                          0.2150921  0.2957633 15580\nyear2004_c                     3.4866284  3.9505772 15580\ndegreebachelor:genderfemale_c -0.5414335  0.3296230 15580\ndegreebachelor:age_c           0.2497957  0.4044807 15580\ndegreebachelor:year2004_c      1.8960373  2.7586110 15580"
  },
  {
    "objectID": "ParameterEstimation.html#sec-Matching",
    "href": "ParameterEstimation.html#sec-Matching",
    "title": "2  線形モデルによるパラメータの推定",
    "section": "2.3 マッチング法による修正",
    "text": "2.3 マッチング法による修正\n\n回帰を行う事前準備としてマッチング法を利用する\n\n重回帰が持つ関数形への依存度を減らせる (Ho et al. 2007)\nMathItパッケージを利用\n\n多数のマッチング法が実装されている\n\n\n2.3.1 Coarsened exact matching\n\nCoarsened exact matching (Iacus, King, and Porro 2012)の実装\n\n連続変数をカテゴリー変数化することで、マッチングできるサンプルサイズを増やすことが期待できる\n\n\n\nfit.m <- matchit(degree ~ gender + age + year,\n                 data = CPSSW9204,\n                 method = \"CEM\"\n                 )\n\n\nマッチング結果の表示\n\n\nfit.m\n\nA matchit object\n - method: Coarsened exact matching\n - number of obs.: 15588 (original), 15588 (matched)\n - target estimand: ATT\n - covariates: gender, age, year\n\n\n\nSample sizesにて、マッチングできなかったサンプル数（985のコントロールグループ中、667サンプルがマッチングできなかった）が確認できる\nマッチング結果の図示\n\n\nfit.m |> \n  summary() |> \n  plot(abs = FALSE)\n\n\n\n\n\nマッチング結果を変数として含んだデータを作成\n\n\ndf <- match.data(fit.m)\n\n\n“subclass”: マッチングしたグループ\n“weights”：マッチング後の推計に用いるウェイト\nマッチングしたデータを用いた推定\n\n新たに作成されるweight (defaltではweights)を用いた、加重推定で実装\n\n\n\nlm_robust(earnings ~ degree + gender + age + year,\n          df,\n          weights = weights,\n          clusters = subclass)\n\n                 Estimate Std. Error     t value     Pr(>|t|)   CI Lower\n(Intercept)    -0.9406001 1.06964454  -0.8793577 3.900258e-01 -3.1770482\ndegreebachelor  5.6973701 0.29536430  19.2892987 8.424314e-21  5.0987422\ngenderfemale   -2.5534913 0.19585455 -13.0376918 1.521310e-14 -2.9520114\nage             0.3855614 0.03430666  11.2386741 8.520762e-10  0.3137177\nyear2004        4.6549789 0.18737754  24.8427793 1.299149e-23  4.2743968\n                 CI Upper       DF\n(Intercept)     1.2958479 19.29879\ndegreebachelor  6.2959981 36.70388\ngenderfemale   -2.1549711 32.88904\nage             0.4574051 18.84870\nyear2004        5.0355610 34.52932\n\n\n\n\n2.3.2 Propensity score with subclassification\n\nCoarsened exact matchingでもマッチングできないサンプルが多数出てくる可能性\n\nとくに\\(X\\)が大量にある場合\n\n1次元の距離指標を用いて、マッチングを行う\n\n距離指標としては、Mahalanobis’ Distance、Propensity scoreなど\n\nここではPropensity score \\(p_d(X)\\)を用いる\n\n\\[p_d(X)\\equiv \\Pr[D=d|X]\\]\n\n属性\\(X\\)のユニットの中で、原因変数の値が\\(d\\)である人の割合\n未知の場合、データから推定する必要がある\n推定された傾向スコアを用いたStratification マッチング (Imbens 2015 の推奨)\n-　ロジットにて傾向スコアを推定\n\n\nfit.m <- matchit(degree ~ gender + age + year,\n                 data = CPSSW9204,\n                 method = \"subclass\",\n                 estimand = \"ATE\"\n                 )\n\n\nマッチング結果\n\n\nsummary(fit.m)\n\n\nCall:\nmatchit(formula = degree ~ gender + age + year, data = CPSSW9204, \n    method = \"subclass\", estimand = \"ATE\")\n\nSummary of Balance for All Data:\n             Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\ndistance            0.4310        0.4180          0.2320     1.1147    0.0648\ngendermale          0.5291        0.6167         -0.1779          .    0.0877\ngenderfemale        0.4709        0.3833          0.1779          .    0.0877\nage                29.6460       29.7982         -0.0534     1.0019    0.0152\nyear1992            0.4487        0.5164         -0.1358          .    0.0677\nyear2004            0.5513        0.4836          0.1358          .    0.0677\n             eCDF Max\ndistance       0.1109\ngendermale     0.0877\ngenderfemale   0.0877\nage            0.0288\nyear1992       0.0677\nyear2004       0.0677\n\nSummary of Balance Across Subclasses\n             Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\ndistance            0.4239        0.4232          0.0118     1.0127    0.0041\ngendermale          0.5787        0.5812         -0.0050          .    0.0025\ngenderfemale        0.4213        0.4188          0.0050          .    0.0025\nage                29.7479       29.7332          0.0052     0.9890    0.0035\nyear1992            0.4828        0.4902         -0.0148          .    0.0074\nyear2004            0.5172        0.5098          0.0148          .    0.0074\n             eCDF Max\ndistance       0.0130\ngendermale     0.0025\ngenderfemale   0.0025\nage            0.0079\nyear1992       0.0074\nyear2004       0.0074\n\nSample Sizes:\n              Control Treated\nAll           8986.   6602.  \nMatched (ESS) 8881.41 6483.64\nMatched       8986.   6602.  \nUnmatched        0.      0.  \nDiscarded        0.      0.  \n\n\n\nマッチング結果の図示\n\n\nfit.m |> \n  summary() |> \n  plot(abs = FALSE)\n\n\n\n\n\nマッチングしたデータを用いた推定\n\n\nlm_robust(earnings ~ degree + gender + age + year,\n          df,\n          weights = weights,\n          clusters = subclass)\n\n                 Estimate Std. Error     t value     Pr(>|t|)   CI Lower\n(Intercept)    -0.9406001 1.06964454  -0.8793577 3.900258e-01 -3.1770482\ndegreebachelor  5.6973701 0.29536430  19.2892987 8.424314e-21  5.0987422\ngenderfemale   -2.5534913 0.19585455 -13.0376918 1.521310e-14 -2.9520114\nage             0.3855614 0.03430666  11.2386741 8.520762e-10  0.3137177\nyear2004        4.6549789 0.18737754  24.8427793 1.299149e-23  4.2743968\n                 CI Upper       DF\n(Intercept)     1.2958479 19.29879\ndegreebachelor  6.2959981 36.70388\ngenderfemale   -2.1549711 32.88904\nage             0.4574051 18.84870\nyear2004        5.0355610 34.52932"
  },
  {
    "objectID": "ParameterEstimation.html#sec-Appendix",
    "href": "ParameterEstimation.html#sec-Appendix",
    "title": "2  線形モデルによるパラメータの推定",
    "section": "2.4 付録：推定結果の保存と表示",
    "text": "2.4 付録：推定結果の保存と表示\n\n2.4.1 Dot-and-Whisker plotによる可視化\n\nDot-and-Whisker図により点推定量と信頼区間を可視化\n\n\nfit.m <- matchit(degree ~ gender + age + year,\n                 data = CPSSW9204,\n                 method = \"CEM\"\n                 )\n\ndf <- match.data(fit.m)\n\nResult1 <- lm_robust(earnings ~ degree + gender + age + year,\n            data = df) |> \n  tidy() |> \n  filter(term == \"degreebachelor\"\n         ) |> \n  mutate(Method = \"OLS\")\n\nResult1 |> \n  ggplot(aes(y = term,\n             x = estimate,\n             xmin = conf.low,\n             xmax = conf.high)\n         ) +\n  geom_pointrange() +\n  geom_vline(xintercept = 0) +\n  theme_bw()\n\n\n\n\n\nResult2 <- lm_robust(earnings ~ degree + gender + age,\n            data = df,\n            weights = weights,\n            clusters = subclass) |> \n  tidy() |> \n  filter(term == \"degreebachelor\"\n         ) |> \n  mutate(Method = \"Matching + OLS\")\n\nResult1 |> \n  bind_rows(Result2) |> \n  ggplot(aes(y = Method,\n             x = estimate,\n             xmin = conf.low,\n             xmax = conf.high)\n         ) +\n  geom_pointrange() +\n  geom_vline(xintercept = 0) +\n  theme_bw()\n\n\n\n\n\n\n\n\nHo, Daniel E., Kosuke Imai, Gary King, and Elizabeth A. Stuart. 2007. “Matching as Nonparametric Preprocessing for Reducing Model Dependence in Parametric Causal Inference.” Political Analysis 15 (3): 199–236. https://doi.org/10.1093/pan/mpl013.\n\n\nIacus, Stefano M., Gary King, and Giuseppe Porro. 2012. “Causal Inference Without Balance Checking: Coarsened Exact Matching.” Political Analysis 20 (1): 1–24. https://doi.org/10.1093/pan/mpr013.\n\n\nImbens, Guido W. 2015. “Matching Methods in Practice: Three Examples.” The Journal of Human Resources 50 (2): 373–419. https://www.jstor.org/stable/24735990.\n\n\nLin, Winston. 2013. “Agnostic Notes on Regression Adjustments to Experimental Data: Reexamining Freedman’s Critique.” The Annals of Applied Statistics 7 (1): 295–318. https://doi.org/10.1214/12-AOAS583."
  },
  {
    "objectID": "Prediction.html",
    "href": "Prediction.html",
    "title": "3  予測",
    "section": "",
    "text": "データと同じ母集団から新しくランダムサンプリングされ、\\(X\\)のみが観察できるサンプルについて\\(Y\\)の値を予測する。\n\nデータ分割を用いたモデル評価を行う"
  },
  {
    "objectID": "Prediction.html#sec-Purpose",
    "href": "Prediction.html#sec-Purpose",
    "title": "3  予測",
    "section": "3.1 問題設定",
    "text": "3.1 問題設定\n\n事前に定義する損失関数の期待値を最小化するような、予測関数\\(f(X)\\)の推定を目指す。\n\n以下ではMean squared error(MSE)を損失関数として用いる。確率変数\\(Y,X\\)について予測問題は以下のように定義できる\n\n\n\\[\\min_{f(X)}MSE = \\int_{x}E[(Y_i-f(x))^2|X_i=x]f(x)dx\\]\n\n一般に以下のように書き換えられる\n\n\\[\\min_{f(X_i)} \\int_{x}E[(\\mu(x)-f(x))^2|X_i=x]f(x)dx\\]$\nただし \\(\\mu(x)=E[Y_i|X_i=x]\\)\n\n上記問題を具体的に解くアルゴリズムとして、ここでは OLS, LASSO, Random Forest、およびそれらのSuperLearnerを実装する。"
  },
  {
    "objectID": "Prediction.html#パッケージ-データ",
    "href": "Prediction.html#パッケージ-データ",
    "title": "3  予測",
    "section": "3.2 パッケージ & データ",
    "text": "3.2 パッケージ & データ\n\nlibrary(tidyverse)\nlibrary(recipes)\nlibrary(mlr3verse) # 機械学習のメタパッケージ\nlibrary(mlr3pipelines) # SuperLearnerを実装する\nlibrary(AER)\n\ndata(\"CPSSW9204\")\n\nset.seed(123)\n\nData <- recipe(earnings~ year + degree + gender + age,\n            CPSSW9204) |> \n  step_dummy(all_nominal_predictors()) |> \n  prep() |> \n  bake(CPSSW9204)"
  },
  {
    "objectID": "Prediction.html#推定",
    "href": "Prediction.html#推定",
    "title": "3  予測",
    "section": "3.3 推定",
    "text": "3.3 推定\n\n3.3.1 推定タスクの定義\n\nTask <- as_task_regr(Data, target = \"earnings\")\n\n\n\n3.3.2 個別推定方法の定義\n\nLearnerLASSO <- lrn(\"regr.cv_glmnet\")\n\nLearnerOLS <- lrn(\"regr.lm\")\n\nLearnerRF <- lrn(\"regr.ranger\")\n\n\n3.3.2.1 SuperLearnerの定義\n\nBaseLearner <- list(\n  LearnerOLS,\n  LearnerLASSO,\n  LearnerRF\n) # 個別推定アルゴリズム\n\nSuperLearner <- lrn(\"regr.lm\",\n                    id = \"SuperLearner\") # 個別予測をまとめるアルゴリズム\n\nLearnerStack <- pipeline_stacking(BaseLearner, SuperLearner) |> \n  as_learner()\n\n\n\n\n3.3.3 サンプル分割の定義\n\nResampleCV <- rsmp(\"cv\")\n\n\n\n3.3.4 評価指標の定義\n\nMesurementR2 <-  msr(\"regr.rsq\")\n\n\n\n3.3.5 交差推定\n\nFitOLS <- resample(Task, LearnerOLS, ResampleCV, store_models = TRUE)\n\nINFO  [19:40:26.262] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 1/10) \nINFO  [19:40:26.288] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 2/10) \nINFO  [19:40:26.299] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 3/10) \nINFO  [19:40:26.308] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 4/10) \nINFO  [19:40:26.320] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 5/10) \nINFO  [19:40:26.328] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 6/10) \nINFO  [19:40:26.340] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 7/10) \nINFO  [19:40:26.349] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 8/10) \nINFO  [19:40:26.357] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 9/10) \nINFO  [19:40:26.369] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 10/10) \n\nFitLASSO <- resample(Task, LearnerLASSO, ResampleCV, store_models = TRUE)\n\nINFO  [19:40:26.679] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 1/10) \nINFO  [19:40:26.930] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 2/10) \nINFO  [19:40:27.128] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 3/10) \nINFO  [19:40:27.223] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 4/10) \nINFO  [19:40:27.309] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 5/10) \nINFO  [19:40:27.492] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 6/10) \nINFO  [19:40:27.570] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 7/10) \nINFO  [19:40:27.662] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 8/10) \nINFO  [19:40:27.849] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 9/10) \nINFO  [19:40:27.926] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 10/10) \n\nFitRF <- resample(Task, LearnerRF, ResampleCV, store_models = TRUE)\n\nINFO  [19:40:28.021] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 1/10) \nINFO  [19:40:28.788] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 2/10) \nINFO  [19:40:29.549] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 3/10) \nINFO  [19:40:30.325] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 4/10) \nINFO  [19:40:31.093] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 5/10) \nINFO  [19:40:31.851] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 6/10) \nINFO  [19:40:32.600] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 7/10) \nINFO  [19:40:33.354] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 8/10) \nINFO  [19:40:34.104] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 9/10) \nINFO  [19:40:34.845] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 10/10) \n\nFitStack <- resample(Task, LearnerStack, ResampleCV, store_models = TRUE)\n\nINFO  [19:40:35.666] [mlr3] Applying learner 'regr.lm.regr.cv_glmnet.regr.ranger.nop.featureunion.SuperLearner' on task 'Data' (iter 1/10) \nINFO  [19:40:35.693] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 1/3) \nINFO  [19:40:35.709] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 2/3) \nINFO  [19:40:35.718] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 3/3) \nINFO  [19:40:35.972] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 1/3) \nINFO  [19:40:36.041] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 2/3) \nINFO  [19:40:36.102] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 3/3) \nINFO  [19:40:36.916] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 1/3) \nINFO  [19:40:37.557] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 2/3) \nINFO  [19:40:38.204] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 3/3) \nINFO  [19:40:39.006] [mlr3] Applying learner 'regr.lm.regr.cv_glmnet.regr.ranger.nop.featureunion.SuperLearner' on task 'Data' (iter 2/10) \nINFO  [19:40:39.028] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 1/3) \nINFO  [19:40:39.036] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 2/3) \nINFO  [19:40:39.044] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 3/3) \nINFO  [19:40:39.156] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 1/3) \nINFO  [19:40:39.216] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 2/3) \nINFO  [19:40:39.392] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 3/3) \nINFO  [19:40:40.192] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 1/3) \nINFO  [19:40:40.842] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 2/3) \nINFO  [19:40:41.479] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 3/3) \nINFO  [19:40:42.262] [mlr3] Applying learner 'regr.lm.regr.cv_glmnet.regr.ranger.nop.featureunion.SuperLearner' on task 'Data' (iter 3/10) \nINFO  [19:40:42.284] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 1/3) \nINFO  [19:40:42.292] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 2/3) \nINFO  [19:40:42.301] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 3/3) \nINFO  [19:40:42.412] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 1/3) \nINFO  [19:40:42.478] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 2/3) \nINFO  [19:40:42.537] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 3/3) \nINFO  [19:40:43.336] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 1/3) \nINFO  [19:40:43.976] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 2/3) \nINFO  [19:40:44.623] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 3/3) \nINFO  [19:40:45.395] [mlr3] Applying learner 'regr.lm.regr.cv_glmnet.regr.ranger.nop.featureunion.SuperLearner' on task 'Data' (iter 4/10) \nINFO  [19:40:45.416] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 1/3) \nINFO  [19:40:45.424] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 2/3) \nINFO  [19:40:45.432] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 3/3) \nINFO  [19:40:45.663] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 1/3) \nINFO  [19:40:45.725] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 2/3) \nINFO  [19:40:45.790] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 3/3) \nINFO  [19:40:46.603] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 1/3) \nINFO  [19:40:47.271] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 2/3) \nINFO  [19:40:47.915] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 3/3) \nINFO  [19:40:48.694] [mlr3] Applying learner 'regr.lm.regr.cv_glmnet.regr.ranger.nop.featureunion.SuperLearner' on task 'Data' (iter 5/10) \nINFO  [19:40:48.715] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 1/3) \nINFO  [19:40:48.723] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 2/3) \nINFO  [19:40:48.735] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 3/3) \nINFO  [19:40:48.960] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 1/3) \nINFO  [19:40:49.022] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 2/3) \nINFO  [19:40:49.084] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 3/3) \nINFO  [19:40:49.893] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 1/3) \nINFO  [19:40:50.665] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 2/3) \nINFO  [19:40:51.338] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 3/3) \nINFO  [19:40:52.168] [mlr3] Applying learner 'regr.lm.regr.cv_glmnet.regr.ranger.nop.featureunion.SuperLearner' on task 'Data' (iter 6/10) \nINFO  [19:40:52.196] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 1/3) \nINFO  [19:40:52.210] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 2/3) \nINFO  [19:40:52.225] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 3/3) \nINFO  [19:40:52.341] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 1/3) \nINFO  [19:40:52.413] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 2/3) \nINFO  [19:40:52.475] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 3/3) \nINFO  [19:40:53.285] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 1/3) \nINFO  [19:40:53.931] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 2/3) \nINFO  [19:40:54.585] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 3/3) \nINFO  [19:40:55.368] [mlr3] Applying learner 'regr.lm.regr.cv_glmnet.regr.ranger.nop.featureunion.SuperLearner' on task 'Data' (iter 7/10) \nINFO  [19:40:55.395] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 1/3) \nINFO  [19:40:55.403] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 2/3) \nINFO  [19:40:55.411] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 3/3) \nINFO  [19:40:55.523] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 1/3) \nINFO  [19:40:55.700] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 2/3) \nINFO  [19:40:55.761] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 3/3) \nINFO  [19:40:56.706] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 1/3) \nINFO  [19:40:57.354] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 2/3) \nINFO  [19:40:58.004] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 3/3) \nINFO  [19:40:58.792] [mlr3] Applying learner 'regr.lm.regr.cv_glmnet.regr.ranger.nop.featureunion.SuperLearner' on task 'Data' (iter 8/10) \nINFO  [19:40:58.822] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 1/3) \nINFO  [19:40:58.830] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 2/3) \nINFO  [19:40:58.838] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 3/3) \nINFO  [19:40:58.943] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 1/3) \nINFO  [19:40:59.004] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 2/3) \nINFO  [19:40:59.071] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 3/3) \nINFO  [19:40:59.863] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 1/3) \nINFO  [19:41:00.501] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 2/3) \nINFO  [19:41:01.134] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 3/3) \nINFO  [19:41:01.907] [mlr3] Applying learner 'regr.lm.regr.cv_glmnet.regr.ranger.nop.featureunion.SuperLearner' on task 'Data' (iter 9/10) \nINFO  [19:41:01.934] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 1/3) \nINFO  [19:41:01.942] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 2/3) \nINFO  [19:41:01.950] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 3/3) \nINFO  [19:41:02.066] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 1/3) \nINFO  [19:41:02.126] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 2/3) \nINFO  [19:41:02.196] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 3/3) \nINFO  [19:41:03.111] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 1/3) \nINFO  [19:41:03.753] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 2/3) \nINFO  [19:41:04.406] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 3/3) \nINFO  [19:41:05.204] [mlr3] Applying learner 'regr.lm.regr.cv_glmnet.regr.ranger.nop.featureunion.SuperLearner' on task 'Data' (iter 10/10) \nINFO  [19:41:05.227] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 1/3) \nINFO  [19:41:05.236] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 2/3) \nINFO  [19:41:05.244] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 3/3) \nINFO  [19:41:05.356] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 1/3) \nINFO  [19:41:05.414] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 2/3) \nINFO  [19:41:05.476] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 3/3) \nINFO  [19:41:06.281] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 1/3) \nINFO  [19:41:06.954] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 2/3) \nINFO  [19:41:07.593] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 3/3) \n\n\n\n\n3.3.6 ベンチマーク・テスト\n\ndesign <- benchmark_grid(\n  tasks = Task,\n  learners = list(LearnerOLS,\n                  LearnerLASSO,\n                  LearnerRF,\n                  LearnerStack),\n  resamplings = ResampleCV\n)\n\nBenchMark <- benchmark(design)\n\nINFO  [19:41:08.650] [mlr3] Running benchmark with 40 resampling iterations \nINFO  [19:41:08.652] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 1/10) \nINFO  [19:41:08.661] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 2/10) \nINFO  [19:41:08.671] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 3/10) \nINFO  [19:41:08.688] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 4/10) \nINFO  [19:41:08.702] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 5/10) \nINFO  [19:41:08.715] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 6/10) \nINFO  [19:41:08.725] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 7/10) \nINFO  [19:41:08.738] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 8/10) \nINFO  [19:41:08.898] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 9/10) \nINFO  [19:41:08.907] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 10/10) \nINFO  [19:41:08.916] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 1/10) \nINFO  [19:41:08.989] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 2/10) \nINFO  [19:41:09.067] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 3/10) \nINFO  [19:41:09.143] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 4/10) \nINFO  [19:41:09.226] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 5/10) \nINFO  [19:41:09.313] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 6/10) \nINFO  [19:41:09.398] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 7/10) \nINFO  [19:41:09.485] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 8/10) \nINFO  [19:41:09.563] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 9/10) \nINFO  [19:41:09.640] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 10/10) \nINFO  [19:41:09.750] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 1/10) \nINFO  [19:41:10.531] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 2/10) \nINFO  [19:41:11.315] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 3/10) \nINFO  [19:41:12.089] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 4/10) \nINFO  [19:41:12.864] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 5/10) \nINFO  [19:41:13.632] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 6/10) \nINFO  [19:41:14.391] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 7/10) \nINFO  [19:41:15.154] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 8/10) \nINFO  [19:41:15.918] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 9/10) \nINFO  [19:41:16.685] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 10/10) \nINFO  [19:41:17.455] [mlr3] Applying learner 'regr.lm.regr.cv_glmnet.regr.ranger.nop.featureunion.SuperLearner' on task 'Data' (iter 1/10) \nINFO  [19:41:17.479] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 1/3) \nINFO  [19:41:17.488] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 2/3) \nINFO  [19:41:17.508] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 3/3) \nINFO  [19:41:17.621] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 1/3) \nINFO  [19:41:17.685] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 2/3) \nINFO  [19:41:17.872] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 3/3) \nINFO  [19:41:18.677] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 1/3) \nINFO  [19:41:19.328] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 2/3) \nINFO  [19:41:19.984] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 3/3) \nINFO  [19:41:20.789] [mlr3] Applying learner 'regr.lm.regr.cv_glmnet.regr.ranger.nop.featureunion.SuperLearner' on task 'Data' (iter 2/10) \nINFO  [19:41:20.811] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 1/3) \nINFO  [19:41:20.820] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 2/3) \nINFO  [19:41:20.828] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 3/3) \nINFO  [19:41:20.939] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 1/3) \nINFO  [19:41:21.008] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 2/3) \nINFO  [19:41:21.075] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 3/3) \nINFO  [19:41:21.890] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 1/3) \nINFO  [19:41:22.546] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 2/3) \nINFO  [19:41:23.204] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 3/3) \nINFO  [19:41:24.016] [mlr3] Applying learner 'regr.lm.regr.cv_glmnet.regr.ranger.nop.featureunion.SuperLearner' on task 'Data' (iter 3/10) \nINFO  [19:41:24.039] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 1/3) \nINFO  [19:41:24.048] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 2/3) \nINFO  [19:41:24.057] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 3/3) \nINFO  [19:41:24.169] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 1/3) \nINFO  [19:41:24.230] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 2/3) \nINFO  [19:41:24.302] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 3/3) \nINFO  [19:41:25.123] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 1/3) \nINFO  [19:41:25.792] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 2/3) \nINFO  [19:41:26.472] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 3/3) \nINFO  [19:41:27.284] [mlr3] Applying learner 'regr.lm.regr.cv_glmnet.regr.ranger.nop.featureunion.SuperLearner' on task 'Data' (iter 4/10) \nINFO  [19:41:27.307] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 1/3) \nINFO  [19:41:27.315] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 2/3) \nINFO  [19:41:27.323] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 3/3) \nINFO  [19:41:27.444] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 1/3) \nINFO  [19:41:27.512] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 2/3) \nINFO  [19:41:27.577] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 3/3) \nINFO  [19:41:28.372] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 1/3) \nINFO  [19:41:29.034] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 2/3) \nINFO  [19:41:29.687] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 3/3) \nINFO  [19:41:30.485] [mlr3] Applying learner 'regr.lm.regr.cv_glmnet.regr.ranger.nop.featureunion.SuperLearner' on task 'Data' (iter 5/10) \nINFO  [19:41:30.507] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 1/3) \nINFO  [19:41:30.516] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 2/3) \nINFO  [19:41:30.525] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 3/3) \nINFO  [19:41:30.640] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 1/3) \nINFO  [19:41:30.833] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 2/3) \nINFO  [19:41:30.897] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 3/3) \nINFO  [19:41:31.705] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 1/3) \nINFO  [19:41:32.354] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 2/3) \nINFO  [19:41:33.026] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 3/3) \nINFO  [19:41:33.838] [mlr3] Applying learner 'regr.lm.regr.cv_glmnet.regr.ranger.nop.featureunion.SuperLearner' on task 'Data' (iter 6/10) \nINFO  [19:41:33.871] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 1/3) \nINFO  [19:41:33.884] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 2/3) \nINFO  [19:41:33.896] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 3/3) \nINFO  [19:41:34.038] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 1/3) \nINFO  [19:41:34.116] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 2/3) \nINFO  [19:41:34.188] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 3/3) \nINFO  [19:41:35.001] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 1/3) \nINFO  [19:41:35.652] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 2/3) \nINFO  [19:41:36.307] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 3/3) \nINFO  [19:41:37.097] [mlr3] Applying learner 'regr.lm.regr.cv_glmnet.regr.ranger.nop.featureunion.SuperLearner' on task 'Data' (iter 7/10) \nINFO  [19:41:37.127] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 1/3) \nINFO  [19:41:37.137] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 2/3) \nINFO  [19:41:37.145] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 3/3) \nINFO  [19:41:37.256] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 1/3) \nINFO  [19:41:37.318] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 2/3) \nINFO  [19:41:37.380] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 3/3) \nINFO  [19:41:38.191] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 1/3) \nINFO  [19:41:38.873] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 2/3) \nINFO  [19:41:39.525] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 3/3) \nINFO  [19:41:40.342] [mlr3] Applying learner 'regr.lm.regr.cv_glmnet.regr.ranger.nop.featureunion.SuperLearner' on task 'Data' (iter 8/10) \nINFO  [19:41:40.371] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 1/3) \nINFO  [19:41:40.379] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 2/3) \nINFO  [19:41:40.387] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 3/3) \nINFO  [19:41:40.505] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 1/3) \nINFO  [19:41:40.571] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 2/3) \nINFO  [19:41:40.639] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 3/3) \nINFO  [19:41:41.608] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 1/3) \nINFO  [19:41:42.279] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 2/3) \nINFO  [19:41:42.935] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 3/3) \nINFO  [19:41:43.759] [mlr3] Applying learner 'regr.lm.regr.cv_glmnet.regr.ranger.nop.featureunion.SuperLearner' on task 'Data' (iter 9/10) \nINFO  [19:41:43.781] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 1/3) \nINFO  [19:41:43.789] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 2/3) \nINFO  [19:41:43.798] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 3/3) \nINFO  [19:41:43.912] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 1/3) \nINFO  [19:41:43.970] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 2/3) \nINFO  [19:41:44.028] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 3/3) \nINFO  [19:41:44.829] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 1/3) \nINFO  [19:41:45.490] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 2/3) \nINFO  [19:41:46.160] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 3/3) \nINFO  [19:41:46.984] [mlr3] Applying learner 'regr.lm.regr.cv_glmnet.regr.ranger.nop.featureunion.SuperLearner' on task 'Data' (iter 10/10) \nINFO  [19:41:47.007] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 1/3) \nINFO  [19:41:47.015] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 2/3) \nINFO  [19:41:47.024] [mlr3] Applying learner 'regr.lm' on task 'Data' (iter 3/3) \nINFO  [19:41:47.145] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 1/3) \nINFO  [19:41:47.203] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 2/3) \nINFO  [19:41:47.268] [mlr3] Applying learner 'regr.cv_glmnet' on task 'Data' (iter 3/3) \nINFO  [19:41:48.084] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 1/3) \nINFO  [19:41:48.744] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 2/3) \nINFO  [19:41:49.397] [mlr3] Applying learner 'regr.ranger' on task 'Data' (iter 3/3) \nINFO  [19:41:50.199] [mlr3] Finished benchmark \n\nBenchMark$aggregate(MesurementR2)\n\n   nr      resample_result task_id\n1:  1 <ResampleResult[21]>    Data\n2:  2 <ResampleResult[21]>    Data\n3:  3 <ResampleResult[21]>    Data\n4:  4 <ResampleResult[21]>    Data\n                                                         learner_id\n1:                                                          regr.lm\n2:                                                   regr.cv_glmnet\n3:                                                      regr.ranger\n4: regr.lm.regr.cv_glmnet.regr.ranger.nop.featureunion.SuperLearner\n   resampling_id iters  regr.rsq\n1:            cv    10 0.2700908\n2:            cv    10 0.2562989\n3:            cv    10 0.2772767\n4:            cv    10 0.2804623"
  },
  {
    "objectID": "CausalMachineLearning.html",
    "href": "CausalMachineLearning.html",
    "title": "4  セミパラメトリック推定",
    "section": "",
    "text": "データと同じ母集団から新しくランダムサンプリングされ、\\(X\\)のみが観察できるサンプルについて\\(Y\\)の値を予測する。\n\nデータ分割を用いたモデル評価を行う"
  },
  {
    "objectID": "CausalMachineLearning.html#問題設定",
    "href": "CausalMachineLearning.html#問題設定",
    "title": "4  セミパラメトリック推定",
    "section": "4.1 問題設定",
    "text": "4.1 問題設定\n\n事前に定義する損失関数の期待値を最小化するような、予測関数\\(f(X)\\)の推定を目指す。\n\n以下ではMean squared error(MSE)を損失関数として用いる。確率変数\\(Y,X\\)について予測問題は以下のように定義できる\n\n\n\\[\\min_{f(X)}MSE = \\int_{x}E[(Y_i-f(x))^2|X_i=x]f(x)dx\\]\n\n一般に以下のように書き換えられる\n\n\\[\\min_{f(X_i)} \\int_{x}E[(\\mu(x)-f(x))^2|X_i=x]f(x)dx\\]$\nただし \\(\\mu(x)=E[Y_i|X_i=x]\\)\n\n上記問題を具体的に解くアルゴリズムとして、ここでは OLS, LASSO, Random Forestを実装する。"
  },
  {
    "objectID": "CausalMachineLearning.html#パッケージ-データ",
    "href": "CausalMachineLearning.html#パッケージ-データ",
    "title": "4  セミパラメトリック推定",
    "section": "4.2 パッケージ & データ",
    "text": "4.2 パッケージ & データ\n\nlibrary(tidyverse)\nlibrary(recipes)\nlibrary(mlr3verse)\nlibrary(mlr3pipelines)\nlibrary(AER)\nlibrary(DoubleML)\n\ndata(\"CPSSW9204\")\n\nset.seed(123)\n\nY <- CPSSW9204$earnings\n\nD <- if_else(CPSSW9204$degree == \"bachelor\",1,0)\n\nX <- recipe(~ year + gender + age,\n            CPSSW9204) |> \n  step_dummy(all_nominal_predictors()) |> \n  prep() |> \n  bake(CPSSW9204,\n       composition = \"matrix\")\n\nData <-  double_ml_data_from_matrix(X=X, \n                                        y=Y, \n                                        d=D)"
  },
  {
    "objectID": "CausalMachineLearning.html#推定",
    "href": "CausalMachineLearning.html#推定",
    "title": "4  セミパラメトリック推定",
    "section": "4.3 推定",
    "text": "4.3 推定\n\n4.3.1 Outcome Model\n\nRegLASSO <- lrn(\"regr.cv_glmnet\",\n  id = \"RegressionLASSO\"\n)\nRegOLS <- lrn(\"regr.lm\",\n  id = \"RegressionOLS\"\n)\n\nRegRF <- lrn(\"regr.ranger\",\n  id = \"RegressionRandomForest\"\n)\n\nProbLASSO <- lrn(\"classif.cv_glmnet\",\n  id = \"ProbLASSO\",\n  predict_type = \"prob\"\n)\n\nProbOLS <- lrn(\"classif.log_reg\",\n  id = \"ProbLM\",\n  predict_type = \"prob\"\n)\n\nProbRF <- lrn(\"classif.ranger\",\n  id = \"ProbRanger\",\n  predict_type = \"prob\"\n)\n\nRegLearners <- list(\n  RegOLS,\n  RegLASSO,\n  RegRF\n)\n\nProbLearners <- list(\n  ProbOLS,\n  ProbLASSO,\n  ProbRF\n)\n\nRegSuperLearner <- lrn(\"regr.lm\",\n                    id = \"RegressionSuperLearner\")\n\nProbSuperLearner <- lrn(\"classif.log_reg\",\n                    id = \"ProbSuperLearner\")\n\n\nRegNuisanceLearner <- pipeline_stacking(RegLearners, RegSuperLearner) |> \n  as_learner()\n\nProbNuisanceLearner <- pipeline_stacking(ProbLearners, ProbSuperLearner) |> \n  as_learner()"
  },
  {
    "objectID": "CausalMachineLearning.html#partial-linear-model",
    "href": "CausalMachineLearning.html#partial-linear-model",
    "title": "4  セミパラメトリック推定",
    "section": "4.4 Partial Linear Model",
    "text": "4.4 Partial Linear Model\n\nFitPLR = DoubleMLPLR$new(Data, \n                         ml_l=RegNuisanceLearner, \n                         ml_m=ProbNuisanceLearner)\n\nFitPLR$fit()\n\nINFO  [19:43:41.548] [mlr3] Applying learner 'RegressionOLS.RegressionLASSO.RegressionRandomForest.nop.featureunion.RegressionSuperLearner' on task 'nuis_l' (iter 1/5) \nINFO  [19:43:41.584] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_l' (iter 1/3) \nINFO  [19:43:41.705] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_l' (iter 2/3) \nINFO  [19:43:41.712] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_l' (iter 3/3) \nINFO  [19:43:41.987] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_l' (iter 1/3) \nINFO  [19:43:42.188] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_l' (iter 2/3) \nINFO  [19:43:42.252] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_l' (iter 3/3) \nINFO  [19:43:42.752] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_l' (iter 1/3) \nINFO  [19:43:43.152] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_l' (iter 2/3) \nINFO  [19:43:43.538] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_l' (iter 3/3) \nINFO  [19:43:44.085] [mlr3] Applying learner 'RegressionOLS.RegressionLASSO.RegressionRandomForest.nop.featureunion.RegressionSuperLearner' on task 'nuis_l' (iter 2/5) \nINFO  [19:43:44.107] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_l' (iter 1/3) \nINFO  [19:43:44.115] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_l' (iter 2/3) \nINFO  [19:43:44.123] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_l' (iter 3/3) \nINFO  [19:43:44.233] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_l' (iter 1/3) \nINFO  [19:43:44.300] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_l' (iter 2/3) \nINFO  [19:43:44.363] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_l' (iter 3/3) \nINFO  [19:43:44.974] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_l' (iter 1/3) \nINFO  [19:43:45.368] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_l' (iter 2/3) \nINFO  [19:43:45.760] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_l' (iter 3/3) \nINFO  [19:43:46.301] [mlr3] Applying learner 'RegressionOLS.RegressionLASSO.RegressionRandomForest.nop.featureunion.RegressionSuperLearner' on task 'nuis_l' (iter 3/5) \nINFO  [19:43:46.325] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_l' (iter 1/3) \nINFO  [19:43:46.333] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_l' (iter 2/3) \nINFO  [19:43:46.340] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_l' (iter 3/3) \nINFO  [19:43:46.448] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_l' (iter 1/3) \nINFO  [19:43:46.626] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_l' (iter 2/3) \nINFO  [19:43:46.683] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_l' (iter 3/3) \nINFO  [19:43:47.166] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_l' (iter 1/3) \nINFO  [19:43:47.559] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_l' (iter 2/3) \nINFO  [19:43:47.942] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_l' (iter 3/3) \nINFO  [19:43:48.484] [mlr3] Applying learner 'RegressionOLS.RegressionLASSO.RegressionRandomForest.nop.featureunion.RegressionSuperLearner' on task 'nuis_l' (iter 4/5) \nINFO  [19:43:48.504] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_l' (iter 1/3) \nINFO  [19:43:48.511] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_l' (iter 2/3) \nINFO  [19:43:48.519] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_l' (iter 3/3) \nINFO  [19:43:48.621] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_l' (iter 1/3) \nINFO  [19:43:48.687] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_l' (iter 2/3) \nINFO  [19:43:48.745] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_l' (iter 3/3) \nINFO  [19:43:49.219] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_l' (iter 1/3) \nINFO  [19:43:49.614] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_l' (iter 2/3) \nINFO  [19:43:50.005] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_l' (iter 3/3) \nINFO  [19:43:50.545] [mlr3] Applying learner 'RegressionOLS.RegressionLASSO.RegressionRandomForest.nop.featureunion.RegressionSuperLearner' on task 'nuis_l' (iter 5/5) \nINFO  [19:43:50.565] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_l' (iter 1/3) \nINFO  [19:43:50.573] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_l' (iter 2/3) \nINFO  [19:43:50.581] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_l' (iter 3/3) \nINFO  [19:43:50.687] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_l' (iter 1/3) \nINFO  [19:43:50.752] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_l' (iter 2/3) \nINFO  [19:43:50.810] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_l' (iter 3/3) \nINFO  [19:43:51.416] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_l' (iter 1/3) \nINFO  [19:43:51.817] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_l' (iter 2/3) \nINFO  [19:43:52.202] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_l' (iter 3/3) \nINFO  [19:43:52.845] [mlr3] Applying learner 'ProbLM.ProbLASSO.ProbRanger.nop.featureunion.ProbSuperLearner' on task 'nuis_m' (iter 1/5) \nINFO  [19:43:52.886] [mlr3] Applying learner 'ProbLM' on task 'nuis_m' (iter 1/3) \nINFO  [19:43:52.907] [mlr3] Applying learner 'ProbLM' on task 'nuis_m' (iter 2/3) \nINFO  [19:43:52.938] [mlr3] Applying learner 'ProbLM' on task 'nuis_m' (iter 3/3) \nINFO  [19:43:53.294] [mlr3] Applying learner 'ProbLASSO' on task 'nuis_m' (iter 1/3) \nINFO  [19:43:53.435] [mlr3] Applying learner 'ProbLASSO' on task 'nuis_m' (iter 2/3) \nINFO  [19:43:53.579] [mlr3] Applying learner 'ProbLASSO' on task 'nuis_m' (iter 3/3) \nINFO  [19:43:54.201] [mlr3] Applying learner 'ProbRanger' on task 'nuis_m' (iter 1/3) \nINFO  [19:43:54.725] [mlr3] Applying learner 'ProbRanger' on task 'nuis_m' (iter 2/3) \nINFO  [19:43:55.247] [mlr3] Applying learner 'ProbRanger' on task 'nuis_m' (iter 3/3) \nINFO  [19:43:56.019] [mlr3] Applying learner 'ProbLM.ProbLASSO.ProbRanger.nop.featureunion.ProbSuperLearner' on task 'nuis_m' (iter 2/5) \nINFO  [19:43:56.054] [mlr3] Applying learner 'ProbLM' on task 'nuis_m' (iter 1/3) \nINFO  [19:43:56.088] [mlr3] Applying learner 'ProbLM' on task 'nuis_m' (iter 2/3) \nINFO  [19:43:56.109] [mlr3] Applying learner 'ProbLM' on task 'nuis_m' (iter 3/3) \nINFO  [19:43:56.336] [mlr3] Applying learner 'ProbLASSO' on task 'nuis_m' (iter 1/3) \nINFO  [19:43:56.475] [mlr3] Applying learner 'ProbLASSO' on task 'nuis_m' (iter 2/3) \nINFO  [19:43:56.610] [mlr3] Applying learner 'ProbLASSO' on task 'nuis_m' (iter 3/3) \nINFO  [19:43:57.241] [mlr3] Applying learner 'ProbRanger' on task 'nuis_m' (iter 1/3) \nINFO  [19:43:57.772] [mlr3] Applying learner 'ProbRanger' on task 'nuis_m' (iter 2/3) \nINFO  [19:43:58.299] [mlr3] Applying learner 'ProbRanger' on task 'nuis_m' (iter 3/3) \nINFO  [19:43:59.083] [mlr3] Applying learner 'ProbLM.ProbLASSO.ProbRanger.nop.featureunion.ProbSuperLearner' on task 'nuis_m' (iter 3/5) \nINFO  [19:43:59.115] [mlr3] Applying learner 'ProbLM' on task 'nuis_m' (iter 1/3) \nINFO  [19:43:59.140] [mlr3] Applying learner 'ProbLM' on task 'nuis_m' (iter 2/3) \nINFO  [19:43:59.160] [mlr3] Applying learner 'ProbLM' on task 'nuis_m' (iter 3/3) \nINFO  [19:43:59.390] [mlr3] Applying learner 'ProbLASSO' on task 'nuis_m' (iter 1/3) \nINFO  [19:43:59.534] [mlr3] Applying learner 'ProbLASSO' on task 'nuis_m' (iter 2/3) \nINFO  [19:43:59.679] [mlr3] Applying learner 'ProbLASSO' on task 'nuis_m' (iter 3/3) \nINFO  [19:44:00.421] [mlr3] Applying learner 'ProbRanger' on task 'nuis_m' (iter 1/3) \nINFO  [19:44:00.931] [mlr3] Applying learner 'ProbRanger' on task 'nuis_m' (iter 2/3) \nINFO  [19:44:01.446] [mlr3] Applying learner 'ProbRanger' on task 'nuis_m' (iter 3/3) \nINFO  [19:44:02.234] [mlr3] Applying learner 'ProbLM.ProbLASSO.ProbRanger.nop.featureunion.ProbSuperLearner' on task 'nuis_m' (iter 4/5) \nINFO  [19:44:02.268] [mlr3] Applying learner 'ProbLM' on task 'nuis_m' (iter 1/3) \nINFO  [19:44:02.287] [mlr3] Applying learner 'ProbLM' on task 'nuis_m' (iter 2/3) \nINFO  [19:44:02.312] [mlr3] Applying learner 'ProbLM' on task 'nuis_m' (iter 3/3) \nINFO  [19:44:02.539] [mlr3] Applying learner 'ProbLASSO' on task 'nuis_m' (iter 1/3) \nINFO  [19:44:02.683] [mlr3] Applying learner 'ProbLASSO' on task 'nuis_m' (iter 2/3) \nINFO  [19:44:02.827] [mlr3] Applying learner 'ProbLASSO' on task 'nuis_m' (iter 3/3) \nINFO  [19:44:03.445] [mlr3] Applying learner 'ProbRanger' on task 'nuis_m' (iter 1/3) \nINFO  [19:44:03.962] [mlr3] Applying learner 'ProbRanger' on task 'nuis_m' (iter 2/3) \nINFO  [19:44:04.484] [mlr3] Applying learner 'ProbRanger' on task 'nuis_m' (iter 3/3) \nINFO  [19:44:05.258] [mlr3] Applying learner 'ProbLM.ProbLASSO.ProbRanger.nop.featureunion.ProbSuperLearner' on task 'nuis_m' (iter 5/5) \nINFO  [19:44:05.290] [mlr3] Applying learner 'ProbLM' on task 'nuis_m' (iter 1/3) \nINFO  [19:44:05.315] [mlr3] Applying learner 'ProbLM' on task 'nuis_m' (iter 2/3) \nINFO  [19:44:05.335] [mlr3] Applying learner 'ProbLM' on task 'nuis_m' (iter 3/3) \nINFO  [19:44:05.573] [mlr3] Applying learner 'ProbLASSO' on task 'nuis_m' (iter 1/3) \nINFO  [19:44:05.721] [mlr3] Applying learner 'ProbLASSO' on task 'nuis_m' (iter 2/3) \nINFO  [19:44:05.863] [mlr3] Applying learner 'ProbLASSO' on task 'nuis_m' (iter 3/3) \nINFO  [19:44:06.500] [mlr3] Applying learner 'ProbRanger' on task 'nuis_m' (iter 1/3) \nINFO  [19:44:07.021] [mlr3] Applying learner 'ProbRanger' on task 'nuis_m' (iter 2/3) \nINFO  [19:44:07.550] [mlr3] Applying learner 'ProbRanger' on task 'nuis_m' (iter 3/3) \n\nprint(FitPLR)\n\n================= DoubleMLPLR Object ==================\n\n\n------------------ Data summary      ------------------\nOutcome variable: y\nTreatment variable(s): d\nCovariates: X1, X2, X3\nInstrument(s): \nNo. Observations: 15588\n\n------------------ Score & algorithm ------------------\nScore function: partialling out\nDML algorithm: dml2\n\n------------------ Machine learner   ------------------\nml_l: RegressionOLS.RegressionLASSO.RegressionRandomForest.nop.featureunion.RegressionSuperLearner\nml_m: ProbLM.ProbLASSO.ProbRanger.nop.featureunion.ProbSuperLearner\n\n------------------ Resampling        ------------------\nNo. folds: 5\nNo. repeated sample splits: 1\nApply cross-fitting: TRUE\n\n------------------ Fit summary       ------------------\n Estimates and significance testing of the effect of target variables\n  Estimate. Std. Error t value Pr(>|t|)    \nd    5.6527     0.1143   49.47   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "CausalMachineLearning.html#aipw",
    "href": "CausalMachineLearning.html#aipw",
    "title": "4  セミパラメトリック推定",
    "section": "4.5 AIPW",
    "text": "4.5 AIPW\n\nFitAIPW = DoubleMLIRM$new(Data, \n                         ml_g=RegNuisanceLearner, \n                         ml_m=ProbNuisanceLearner)\n\nFitAIPW$fit()\n\nINFO  [19:44:08.612] [mlr3] Applying learner 'ProbLM.ProbLASSO.ProbRanger.nop.featureunion.ProbSuperLearner' on task 'nuis_m' (iter 1/5) \nINFO  [19:44:08.792] [mlr3] Applying learner 'ProbLM' on task 'nuis_m' (iter 1/3) \nINFO  [19:44:08.812] [mlr3] Applying learner 'ProbLM' on task 'nuis_m' (iter 2/3) \nINFO  [19:44:08.833] [mlr3] Applying learner 'ProbLM' on task 'nuis_m' (iter 3/3) \nINFO  [19:44:09.063] [mlr3] Applying learner 'ProbLASSO' on task 'nuis_m' (iter 1/3) \nINFO  [19:44:09.212] [mlr3] Applying learner 'ProbLASSO' on task 'nuis_m' (iter 2/3) \nINFO  [19:44:09.365] [mlr3] Applying learner 'ProbLASSO' on task 'nuis_m' (iter 3/3) \nINFO  [19:44:10.010] [mlr3] Applying learner 'ProbRanger' on task 'nuis_m' (iter 1/3) \nINFO  [19:44:10.540] [mlr3] Applying learner 'ProbRanger' on task 'nuis_m' (iter 2/3) \nINFO  [19:44:11.079] [mlr3] Applying learner 'ProbRanger' on task 'nuis_m' (iter 3/3) \nINFO  [19:44:11.860] [mlr3] Applying learner 'ProbLM.ProbLASSO.ProbRanger.nop.featureunion.ProbSuperLearner' on task 'nuis_m' (iter 2/5) \nINFO  [19:44:11.892] [mlr3] Applying learner 'ProbLM' on task 'nuis_m' (iter 1/3) \nINFO  [19:44:11.913] [mlr3] Applying learner 'ProbLM' on task 'nuis_m' (iter 2/3) \nINFO  [19:44:11.941] [mlr3] Applying learner 'ProbLM' on task 'nuis_m' (iter 3/3) \nINFO  [19:44:12.167] [mlr3] Applying learner 'ProbLASSO' on task 'nuis_m' (iter 1/3) \nINFO  [19:44:12.305] [mlr3] Applying learner 'ProbLASSO' on task 'nuis_m' (iter 2/3) \nINFO  [19:44:12.443] [mlr3] Applying learner 'ProbLASSO' on task 'nuis_m' (iter 3/3) \nINFO  [19:44:13.068] [mlr3] Applying learner 'ProbRanger' on task 'nuis_m' (iter 1/3) \nINFO  [19:44:13.600] [mlr3] Applying learner 'ProbRanger' on task 'nuis_m' (iter 2/3) \nINFO  [19:44:14.116] [mlr3] Applying learner 'ProbRanger' on task 'nuis_m' (iter 3/3) \nINFO  [19:44:14.894] [mlr3] Applying learner 'ProbLM.ProbLASSO.ProbRanger.nop.featureunion.ProbSuperLearner' on task 'nuis_m' (iter 3/5) \nINFO  [19:44:14.938] [mlr3] Applying learner 'ProbLM' on task 'nuis_m' (iter 1/3) \nINFO  [19:44:14.958] [mlr3] Applying learner 'ProbLM' on task 'nuis_m' (iter 2/3) \nINFO  [19:44:14.979] [mlr3] Applying learner 'ProbLM' on task 'nuis_m' (iter 3/3) \nINFO  [19:44:15.218] [mlr3] Applying learner 'ProbLASSO' on task 'nuis_m' (iter 1/3) \nINFO  [19:44:15.362] [mlr3] Applying learner 'ProbLASSO' on task 'nuis_m' (iter 2/3) \nINFO  [19:44:15.510] [mlr3] Applying learner 'ProbLASSO' on task 'nuis_m' (iter 3/3) \nINFO  [19:44:16.135] [mlr3] Applying learner 'ProbRanger' on task 'nuis_m' (iter 1/3) \nINFO  [19:44:16.670] [mlr3] Applying learner 'ProbRanger' on task 'nuis_m' (iter 2/3) \nINFO  [19:44:17.206] [mlr3] Applying learner 'ProbRanger' on task 'nuis_m' (iter 3/3) \nINFO  [19:44:17.991] [mlr3] Applying learner 'ProbLM.ProbLASSO.ProbRanger.nop.featureunion.ProbSuperLearner' on task 'nuis_m' (iter 4/5) \nINFO  [19:44:18.029] [mlr3] Applying learner 'ProbLM' on task 'nuis_m' (iter 1/3) \nINFO  [19:44:18.050] [mlr3] Applying learner 'ProbLM' on task 'nuis_m' (iter 2/3) \nINFO  [19:44:18.091] [mlr3] Applying learner 'ProbLM' on task 'nuis_m' (iter 3/3) \nINFO  [19:44:18.343] [mlr3] Applying learner 'ProbLASSO' on task 'nuis_m' (iter 1/3) \nINFO  [19:44:18.491] [mlr3] Applying learner 'ProbLASSO' on task 'nuis_m' (iter 2/3) \nINFO  [19:44:18.629] [mlr3] Applying learner 'ProbLASSO' on task 'nuis_m' (iter 3/3) \nINFO  [19:44:19.260] [mlr3] Applying learner 'ProbRanger' on task 'nuis_m' (iter 1/3) \nINFO  [19:44:19.790] [mlr3] Applying learner 'ProbRanger' on task 'nuis_m' (iter 2/3) \nINFO  [19:44:20.314] [mlr3] Applying learner 'ProbRanger' on task 'nuis_m' (iter 3/3) \nINFO  [19:44:21.097] [mlr3] Applying learner 'ProbLM.ProbLASSO.ProbRanger.nop.featureunion.ProbSuperLearner' on task 'nuis_m' (iter 5/5) \nINFO  [19:44:21.130] [mlr3] Applying learner 'ProbLM' on task 'nuis_m' (iter 1/3) \nINFO  [19:44:21.158] [mlr3] Applying learner 'ProbLM' on task 'nuis_m' (iter 2/3) \nINFO  [19:44:21.178] [mlr3] Applying learner 'ProbLM' on task 'nuis_m' (iter 3/3) \nINFO  [19:44:21.432] [mlr3] Applying learner 'ProbLASSO' on task 'nuis_m' (iter 1/3) \nINFO  [19:44:21.586] [mlr3] Applying learner 'ProbLASSO' on task 'nuis_m' (iter 2/3) \nINFO  [19:44:21.728] [mlr3] Applying learner 'ProbLASSO' on task 'nuis_m' (iter 3/3) \nINFO  [19:44:22.367] [mlr3] Applying learner 'ProbRanger' on task 'nuis_m' (iter 1/3) \nINFO  [19:44:22.932] [mlr3] Applying learner 'ProbRanger' on task 'nuis_m' (iter 2/3) \nINFO  [19:44:23.474] [mlr3] Applying learner 'ProbRanger' on task 'nuis_m' (iter 3/3) \nINFO  [19:44:24.517] [mlr3] Applying learner 'RegressionOLS.RegressionLASSO.RegressionRandomForest.nop.featureunion.RegressionSuperLearner' on task 'nuis_g0' (iter 1/5) \nINFO  [19:44:24.539] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_g0' (iter 1/3) \nINFO  [19:44:24.546] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_g0' (iter 2/3) \nINFO  [19:44:24.553] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_g0' (iter 3/3) \nINFO  [19:44:24.644] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_g0' (iter 1/3) \nINFO  [19:44:24.685] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_g0' (iter 2/3) \nINFO  [19:44:24.730] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_g0' (iter 3/3) \nINFO  [19:44:25.018] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_g0' (iter 1/3) \nINFO  [19:44:25.248] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_g0' (iter 2/3) \nINFO  [19:44:25.468] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_g0' (iter 3/3) \nINFO  [19:44:25.838] [mlr3] Applying learner 'RegressionOLS.RegressionLASSO.RegressionRandomForest.nop.featureunion.RegressionSuperLearner' on task 'nuis_g0' (iter 2/5) \nINFO  [19:44:25.860] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_g0' (iter 1/3) \nINFO  [19:44:25.867] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_g0' (iter 2/3) \nINFO  [19:44:25.876] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_g0' (iter 3/3) \nINFO  [19:44:25.957] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_g0' (iter 1/3) \nINFO  [19:44:25.999] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_g0' (iter 2/3) \nINFO  [19:44:26.054] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_g0' (iter 3/3) \nINFO  [19:44:26.333] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_g0' (iter 1/3) \nINFO  [19:44:26.548] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_g0' (iter 2/3) \nINFO  [19:44:26.760] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_g0' (iter 3/3) \nINFO  [19:44:27.117] [mlr3] Applying learner 'RegressionOLS.RegressionLASSO.RegressionRandomForest.nop.featureunion.RegressionSuperLearner' on task 'nuis_g0' (iter 3/5) \nINFO  [19:44:27.137] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_g0' (iter 1/3) \nINFO  [19:44:27.144] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_g0' (iter 2/3) \nINFO  [19:44:27.151] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_g0' (iter 3/3) \nINFO  [19:44:27.236] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_g0' (iter 1/3) \nINFO  [19:44:27.279] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_g0' (iter 2/3) \nINFO  [19:44:27.321] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_g0' (iter 3/3) \nINFO  [19:44:27.598] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_g0' (iter 1/3) \nINFO  [19:44:27.812] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_g0' (iter 2/3) \nINFO  [19:44:28.027] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_g0' (iter 3/3) \nINFO  [19:44:28.389] [mlr3] Applying learner 'RegressionOLS.RegressionLASSO.RegressionRandomForest.nop.featureunion.RegressionSuperLearner' on task 'nuis_g0' (iter 4/5) \nINFO  [19:44:28.409] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_g0' (iter 1/3) \nINFO  [19:44:28.416] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_g0' (iter 2/3) \nINFO  [19:44:28.432] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_g0' (iter 3/3) \nINFO  [19:44:28.510] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_g0' (iter 1/3) \nINFO  [19:44:28.557] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_g0' (iter 2/3) \nINFO  [19:44:28.603] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_g0' (iter 3/3) \nINFO  [19:44:28.899] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_g0' (iter 1/3) \nINFO  [19:44:29.113] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_g0' (iter 2/3) \nINFO  [19:44:29.333] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_g0' (iter 3/3) \nINFO  [19:44:29.697] [mlr3] Applying learner 'RegressionOLS.RegressionLASSO.RegressionRandomForest.nop.featureunion.RegressionSuperLearner' on task 'nuis_g0' (iter 5/5) \nINFO  [19:44:29.717] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_g0' (iter 1/3) \nINFO  [19:44:29.724] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_g0' (iter 2/3) \nINFO  [19:44:29.732] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_g0' (iter 3/3) \nINFO  [19:44:29.821] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_g0' (iter 1/3) \nINFO  [19:44:29.867] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_g0' (iter 2/3) \nINFO  [19:44:29.916] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_g0' (iter 3/3) \nINFO  [19:44:30.204] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_g0' (iter 1/3) \nINFO  [19:44:30.440] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_g0' (iter 2/3) \nINFO  [19:44:30.663] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_g0' (iter 3/3) \nINFO  [19:44:31.258] [mlr3] Applying learner 'RegressionOLS.RegressionLASSO.RegressionRandomForest.nop.featureunion.RegressionSuperLearner' on task 'nuis_g1' (iter 1/5) \nINFO  [19:44:31.282] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_g1' (iter 1/3) \nINFO  [19:44:31.290] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_g1' (iter 2/3) \nINFO  [19:44:31.297] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_g1' (iter 3/3) \nINFO  [19:44:31.379] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_g1' (iter 1/3) \nINFO  [19:44:31.429] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_g1' (iter 2/3) \nINFO  [19:44:31.467] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_g1' (iter 3/3) \nINFO  [19:44:31.720] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_g1' (iter 1/3) \nINFO  [19:44:31.871] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_g1' (iter 2/3) \nINFO  [19:44:32.013] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_g1' (iter 3/3) \nINFO  [19:44:32.303] [mlr3] Applying learner 'RegressionOLS.RegressionLASSO.RegressionRandomForest.nop.featureunion.RegressionSuperLearner' on task 'nuis_g1' (iter 2/5) \nINFO  [19:44:32.323] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_g1' (iter 1/3) \nINFO  [19:44:32.331] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_g1' (iter 2/3) \nINFO  [19:44:32.338] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_g1' (iter 3/3) \nINFO  [19:44:32.408] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_g1' (iter 1/3) \nINFO  [19:44:32.451] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_g1' (iter 2/3) \nINFO  [19:44:32.486] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_g1' (iter 3/3) \nINFO  [19:44:32.739] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_g1' (iter 1/3) \nINFO  [19:44:32.884] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_g1' (iter 2/3) \nINFO  [19:44:33.027] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_g1' (iter 3/3) \nINFO  [19:44:33.312] [mlr3] Applying learner 'RegressionOLS.RegressionLASSO.RegressionRandomForest.nop.featureunion.RegressionSuperLearner' on task 'nuis_g1' (iter 3/5) \nINFO  [19:44:33.333] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_g1' (iter 1/3) \nINFO  [19:44:33.340] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_g1' (iter 2/3) \nINFO  [19:44:33.348] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_g1' (iter 3/3) \nINFO  [19:44:33.424] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_g1' (iter 1/3) \nINFO  [19:44:33.466] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_g1' (iter 2/3) \nINFO  [19:44:33.501] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_g1' (iter 3/3) \nINFO  [19:44:33.750] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_g1' (iter 1/3) \nINFO  [19:44:33.911] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_g1' (iter 2/3) \nINFO  [19:44:34.061] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_g1' (iter 3/3) \nINFO  [19:44:34.340] [mlr3] Applying learner 'RegressionOLS.RegressionLASSO.RegressionRandomForest.nop.featureunion.RegressionSuperLearner' on task 'nuis_g1' (iter 4/5) \nINFO  [19:44:34.359] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_g1' (iter 1/3) \nINFO  [19:44:34.367] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_g1' (iter 2/3) \nINFO  [19:44:34.374] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_g1' (iter 3/3) \nINFO  [19:44:34.449] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_g1' (iter 1/3) \nINFO  [19:44:34.490] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_g1' (iter 2/3) \nINFO  [19:44:34.529] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_g1' (iter 3/3) \nINFO  [19:44:34.781] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_g1' (iter 1/3) \nINFO  [19:44:34.927] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_g1' (iter 2/3) \nINFO  [19:44:35.072] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_g1' (iter 3/3) \nINFO  [19:44:35.365] [mlr3] Applying learner 'RegressionOLS.RegressionLASSO.RegressionRandomForest.nop.featureunion.RegressionSuperLearner' on task 'nuis_g1' (iter 5/5) \nINFO  [19:44:35.385] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_g1' (iter 1/3) \nINFO  [19:44:35.391] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_g1' (iter 2/3) \nINFO  [19:44:35.398] [mlr3] Applying learner 'RegressionOLS' on task 'nuis_g1' (iter 3/3) \nINFO  [19:44:35.473] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_g1' (iter 1/3) \nINFO  [19:44:35.514] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_g1' (iter 2/3) \nINFO  [19:44:35.553] [mlr3] Applying learner 'RegressionLASSO' on task 'nuis_g1' (iter 3/3) \nINFO  [19:44:35.797] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_g1' (iter 1/3) \nINFO  [19:44:35.966] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_g1' (iter 2/3) \nINFO  [19:44:36.128] [mlr3] Applying learner 'RegressionRandomForest' on task 'nuis_g1' (iter 3/3) \n\nprint(FitAIPW)\n\n================= DoubleMLIRM Object ==================\n\n\n------------------ Data summary      ------------------\nOutcome variable: y\nTreatment variable(s): d\nCovariates: X1, X2, X3\nInstrument(s): \nNo. Observations: 15588\n\n------------------ Score & algorithm ------------------\nScore function: ATE\nDML algorithm: dml2\n\n------------------ Machine learner   ------------------\nml_g: RegressionOLS.RegressionLASSO.RegressionRandomForest.nop.featureunion.RegressionSuperLearner\nml_m: ProbLM.ProbLASSO.ProbRanger.nop.featureunion.ProbSuperLearner\n\n------------------ Resampling        ------------------\nNo. folds: 5\nNo. repeated sample splits: 1\nApply cross-fitting: TRUE\n\n------------------ Fit summary       ------------------\n Estimates and significance testing of the effect of target variables\n  Estimate. Std. Error t value Pr(>|t|)    \nd    5.6285     0.1136   49.54   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "5  付録: 記述統計",
    "section": "",
    "text": "関心のあるグループ \\((D)\\) ごとに記述統計をまとめる\nSection 5.2 記述統計表を作成\nSection 5.3 変数の分布がバランスしているかどうか、図示する"
  },
  {
    "objectID": "summary.html#パッケージ-データ",
    "href": "summary.html#パッケージ-データ",
    "title": "5  付録: 記述統計",
    "section": "5.1 パッケージ & データ",
    "text": "5.1 パッケージ & データ\n\nlibrary(tidyverse)\nlibrary(AER)\nlibrary(cobalt)\nlibrary(gtsummary)\n\ndata(\"CPSSW9204\")\n\n\ngtsummary : 記述統計表作成\ncobalt : 図作成"
  },
  {
    "objectID": "summary.html#sec-Table",
    "href": "summary.html#sec-Table",
    "title": "5  付録: 記述統計",
    "section": "5.2 記述統計評",
    "text": "5.2 記述統計評\n\n\\(D=degree\\) ごとに以下を表示\n\n連続変数については、 “中央値(下位25%, 上位25%)”\nカテゴリー変数について、 “サンプルサイズ(割合)”\n\n\n\nCPSSW9204 |> \n  tbl_summary(by = \"degree\")\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      highschool, N = 8,9861\n      bachelor, N = 6,6021\n    \n  \n  \n    year\n\n\n    1992\n4,640 (52%)\n2,962 (45%)\n    2004\n4,346 (48%)\n3,640 (55%)\n    earnings\n11 (8, 14)\n16 (12, 21)\n    gender\n\n\n    male\n5,542 (62%)\n3,493 (53%)\n    female\n3,444 (38%)\n3,109 (47%)\n    age\n30 (27, 32)\n30 (27, 32)\n  \n  \n  \n    \n      1 n (%); Median (IQR)"
  },
  {
    "objectID": "summary.html#sec-Figure",
    "href": "summary.html#sec-Figure",
    "title": "5  付録: 記述統計",
    "section": "5.3 記述統計評",
    "text": "5.3 記述統計評\n\nYの平均差/Yの標準偏差を報告 (Imbens (2015) などで推奨)\n\n\nbal.tab(degree ~ gender + age + year,\n                CPSSW9204,\n        binary = \"std\", continuous = \"std\") |> \n  plot()\n\n\n\n\n\n女性かつ近年、かつ年齢が若い方が大卒比率が高い\n\n\n\n\n\nImbens, Guido W. 2015. “Matching Methods in Practice: Three Examples.” The Journal of Human Resources 50 (2): 373–419. https://www.jstor.org/stable/24735990."
  },
  {
    "objectID": "PreProcess.html",
    "href": "PreProcess.html",
    "title": "6  付録: データ整備",
    "section": "",
    "text": "library(tidyverse)\nlibrary(AER)\nlibrary(recipes)\n\ndata(\"CPSSW9204\")\n\n\ntidyverse : 個別変数についてのデータ加工関数群を提供\nrecipes : 統合的なデータ加工関数を提供"
  },
  {
    "objectID": "PreProcess.html#recipes",
    "href": "PreProcess.html#recipes",
    "title": "6  付録: データ整備",
    "section": "6.2 recipes",
    "text": "6.2 recipes\n\nX <- recipe(earnings ~ degree + year + gender + age,\n            CPSSW9204) |> # 推定式を定義\n  update_role(degree,\n              new_role = \"treatment\") |> # degreeをtreatmentに指定\n  step_unknown(all_nominal_predictors()) |> # 非数値変数について、欠損値を\"unknown\"に変更\n  step_other(all_nominal_predictors()) |> # 非数値変数について、小規模グループを\"other\"に変更\n  step_dummy(all_nominal_predictors()) |> # 非数値変数をダミー変数に変換\n  step_indicate_na(all_numeric_predictors()) |> # 数値変数について、欠損ダミーを作成\n  step_impute_median(all_numeric_predictors()) |> # 数値変数について、欠損値に中央値を補完\n  step_nzv(all_numeric_predictors()) |> # 数値変数について、 変動が少ない変数を除外\n  step_corr(all_numeric_predictors()) |> # 相関が強い変数を除去\n  prep() |> \n  bake(CPSSW9204)"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Ho, Daniel E., Kosuke Imai, Gary King, and Elizabeth A. Stuart. 2007.\n“Matching as Nonparametric Preprocessing for Reducing Model\nDependence in Parametric Causal Inference.” Political\nAnalysis 15 (3): 199–236. https://doi.org/10.1093/pan/mpl013.\n\n\nIacus, Stefano M., Gary King, and Giuseppe Porro. 2012. “Causal\nInference Without Balance Checking: Coarsened Exact Matching.”\nPolitical Analysis 20 (1): 1–24. https://doi.org/10.1093/pan/mpr013.\n\n\nImbens, Guido W. 2015. “Matching Methods in Practice: Three\nExamples.” The Journal of Human Resources 50 (2):\n373–419. https://www.jstor.org/stable/24735990.\n\n\nLin, Winston. 2013. “Agnostic Notes on Regression Adjustments to\nExperimental Data: Reexamining Freedman’s Critique.”\nThe Annals of Applied Statistics 7 (1): 295–318. https://doi.org/10.1214/12-AOAS583."
  }
]