{
  "hash": "4d9c8bbadf102aff3d5d6a5e6f5970dd",
  "result": {
    "markdown": "# 予測 {#sec-Prediction}\n\n- 手持ちのデータと同じ母集団から新しくランダムサンプリングされ、$X$のみが観察できるサンプルについて$Y$の値を予測する。\n\n  - データ分割を用いたモデル選択、評価を行う\n\n## 問題設定\n\n- 事前に定義する損失関数の母平均 (Population Risk) を最小化するような、予測関数$f(X)$の推定を目指す。\n\n  - 以下ではMean squared error(MSE)を損失関数として用いる。確率変数$Y,X$について予測問題は以下のように定義できる\n\n\n$$\\min_{f(X)}MSE = \\int_{x}E[(Y_i-f(x))^2|X_i=x]g(x)dx$$\n\n\n- $g(x)$ は$x$の分布関数\n\n  - 一般に以下の最適化問題の解と一致\n\n\n$$\\min_{f(X_i)} \\int_{x}E[(\\mu(x)-f(x))^2|X_i=x]g(x)dx$$$\n\n\nただし $\\mu(x)=E[Y_i|X_i=x]$\n\n- 上記問題を具体的に解くアルゴリズムとして、ここでは OLS, LASSO, Random Forest、およびそれらのSuperLearnerを実装する。\n\n## 実装\n\n- 以下のPipelineを実装\n\n\n```{mermaid}\nflowchart TB\n  A[データとパッケージの読み込み] --> B[予測タスクの定義/サンプル分割]\n  B --> C1[BuildIn 推定アルゴリズムの定義]\n  B --> C2[BuildIn + 前処理 推定アルゴリズムの定義]\n  B --> C3[BuildIn + 前処理 + Tuning 推定アルゴリズムの定義]\n  C1 --> C4[Super Learnerの定義]\n  C2 --> C4[Super Learnerの定義]\n  C3 --> C4[Super Learnerの定義]\n  C1 --> D[Trainデータのみを用いたベンチマーク]\n  C2 --> D[Trainデータのみを用いたベンチマーク]\n  C3 --> D[Trainデータのみを用いたベンチマーク]\n  C4 --> D[Trainデータのみを用いたベンチマーク]\n  D --> E[最善の予測モデルを用いた最終推計]\n  E --> F[Testデータによる評価]\n```\n\n\n\n### パッケージ & データ\n\n- ここではpipelinesによるデータ整備は行わない (暫定的)\n\n- 追加でlgr (表示するメッセージを操作), future (並列計算)  パッケージを使用\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(mlr3verse) # 機械学習のメタパッケージ\nlibrary(mlr3pipelines) # SuperLearnerの実装\n\nRaw <- read_csv(\"ExampleData/Example.csv\")\n\nset.seed(123)\n```\n:::\n\n\n### 推定タスクの定義\n\n- 分割数、繰り返し計算回数は最小限に設定\n\n    - 実戦では増やす\n\n\n::: {.cell}\n\n```{.r .cell-code}\nTask <- as_task_regr(Raw, target = \"Price\") # Task設定\n\nGroup <- partition(Task, ratio = 0.8) # Train/Test分割\n\nR2 <-  msr(\"regr.rsq\") # R2で評価\n\nCV <- rsmp(\"cv\",folds = 2) # 2分割交差検証\n\nTerminal = trm(\"evals\",\n               n_evals = 20) # 20回の繰り返し評価\n\nTuner <- tnr(\"grid_search\",\n             resolution = 20) # 20回のグリッドサーチ\n```\n:::\n\n\n### PreProcess\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMutate = po(\"mutate\") # データ加工\nMutate$param_set$values$mutation = list(\n  Size2 = ~ Size*Size,\n  TradeQ2 = ~ TradeQ*TradeQ,\n  BuildYear2 = ~BuildYear*BuildYear,\n  Distance2 = ~Distance*Distance,\n  Size_TradeQ = ~Size*TradeQ,\n  Size_BuildYear = ~Size*BuildYear,\n  Size_Distance = ~ Size*Distance,\n  TradeQ_BuildYear = ~TradeQ*BuildYear,\n  TradeQ_Distance = ~TradeQ*Distance,\n  BuildYear_Distance = ~BuildYear*Distance\n) # 二乗項と交差項の作成\n\nScale = po(\"scale\") # 標準化\n```\n:::\n\n\n\n### 個別推定方法の定義\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSimpleOLS <- lrn(\"regr.lm\", id = \"SimpleOLS\")\n\nOLS <- Mutate %>>% Scale %>>% lrn(\"regr.lm\") |> as_learner()\nOLS$id <- \"OLS\"\nRandomForest <- lrn(\"regr.ranger\")\n\nTree <- lrn(\"regr.rpart\")\n```\n:::\n\n\n### チューニング付き推定方法の定義\n\n\n::: {.cell}\n\n```{.r .cell-code}\nLASSO <- AutoTuner$new(\n  learner = lrn(\"regr.glmnet\"),\n  resampling = CV,\n  measure = R2,\n  search_space = ps(\n    lambda = p_dbl(lower = 0, upper = 5)\n    ),\n  terminator = Terminal,\n  tuner = Tuner\n) # lambdaをチューニング (LASSO)\n\nLASSO <- Mutate %>>% Scale %>>% LASSO |> as_learner()\nLASSO$id <- \"LASSO\"\n\nPrunedTree <- AutoTuner$new(\n  learner = lrn(\"regr.rpart\"),\n  resampling = CV,\n  measure = R2,\n  search_space = ps(\n    cp = p_dbl(lower = 0, upper = 0.1)\n    ),\n  terminator = Terminal,\n  tuner = Tuner\n) # cpをチューニング\n\nPrunedTree$id <- \"PrunedTree\" # Pruned TreeとIDづけ\n\nElasticNet <- AutoTuner$new(\n  learner = lrn(\"regr.glmnet\"),\n  resampling = CV,\n  measure = R2,\n  search_space = ps(\n    lambda = p_dbl(lower = 0, upper = 5),\n    alpha = p_dbl(lower = 0,upper = 1)\n    ),\n  terminator = Terminal,\n  tuner = Tuner\n) # lambdaとalphaをチューニング\n\nElasticNet <- Mutate %>>% Scale %>>% ElasticNet |> as_learner()\n\nElasticNet$id <- \"ElasticNet\"\n```\n:::\n\n\n### SuperLearnerの定義\n\n\n::: {.cell}\n\n```{.r .cell-code}\nBaseLearner <- list(\n  OLS,\n  SimpleOLS,\n  RandomForest,\n  Tree,\n  PrunedTree,\n  ElasticNet,\n  LASSO\n) # 個別推定アルゴリズム\n\nSuperLearner <- lrn(\"regr.lm\",\n                    id = \"SuperLearner\") # 個別予測をまとめるアルゴリズム\n\nStacking <- pipeline_stacking(BaseLearner, SuperLearner) |> \n  as_learner() # SuperLearnerの定義\n\nStacking$id <- \"Stacking\"\n```\n:::\n\n\n### ベンチマーク・テスト\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDesign <- benchmark_grid(\n  tasks = list(Task$clone()$filter(Group$train)),\n  learners = list(\n    OLS,\n    SimpleOLS,\n    LASSO,\n    RandomForest,\n    Tree,\n    PrunedTree,\n    ElasticNet,\n    Stacking\n  ),\n  resamplings = CV\n)\n\nlgr::get_logger(\"mlr3\")$set_threshold(\"error\") # Errorのみを表示\nlgr::get_logger(\"bbotk\")$set_threshold(\"error\") # Errorのみを表示\nfuture::plan(\"multisession\") # 並列処理\n\nBenchMark <- benchmark(Design)\n\nBenchMark$aggregate(R2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   nr      resample_result task_id  learner_id resampling_id iters  regr.rsq\n1:  1 <ResampleResult[21]>     Raw         OLS            cv     2 0.4689119\n2:  2 <ResampleResult[21]>     Raw   SimpleOLS            cv     2 0.4239997\n3:  3 <ResampleResult[21]>     Raw       LASSO            cv     2 0.4612200\n4:  4 <ResampleResult[21]>     Raw regr.ranger            cv     2 0.4799319\n5:  5 <ResampleResult[21]>     Raw  regr.rpart            cv     2 0.3495715\n6:  6 <ResampleResult[21]>     Raw  PrunedTree            cv     2 0.3832679\n7:  7 <ResampleResult[21]>     Raw  ElasticNet            cv     2 0.4529826\n8:  8 <ResampleResult[21]>     Raw    Stacking            cv     2 0.4807756\n```\n:::\n:::\n\n\n- RandomForestとStackingはComparableな性能\n\n    - とりあえずStackingを採用\n    \n### 最終モデル\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSuperLearner$train(Task, row_ids = Group$train)\n\nSuperLearner$predict(Task, Group$test)$score(R2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n regr.rsq \n0.5220606 \n```\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}