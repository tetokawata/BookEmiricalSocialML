{
  "hash": "11fc7e7a697d784372cbdcfc4ec6b535",
  "result": {
    "markdown": "# 予測 {#sec-Prediction}\n\n- データと同じ母集団から新しくランダムサンプリングされ、$X$のみが観察できるサンプルについて$Y$の値を予測する。\n\n  - データ分割を用いたモデル評価を行う\n\n## 問題設定\n\n- 事前に定義する損失関数の期待値を最小化するような、予測関数$f(X)$の推定を目指す。\n\n  - 以下ではMean squared error(MSE)を損失関数として用いる。確率変数$Y,X$について予測問題は以下のように定義できる\n\n\n$$\\min_{f(X)}MSE = \\int_{x}E[(Y_i-f(x))^2|X_i=x]f(x)dx$$\n\n\n  - 一般に以下のように書き換えられる\n\n\n$$\\min_{f(X_i)} \\int_{x}E[(\\mu(x)-f(x))^2|X_i=x]f(x)dx$$$\n\n\nただし $\\mu(x)=E[Y_i|X_i=x]$\n\n- 上記問題を具体的に解くアルゴリズムとして、ここでは OLS, LASSO, Random Forest、およびそれらのSuperLearnerを実装する。\n\n## パッケージ & データ\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(recipes)\nlibrary(mlr3verse) # 機械学習のメタパッケージ\nlibrary(mlr3pipelines) # SuperLearnerを実装する\nlibrary(mlr3tuning)\nlibrary(AER)\n\ndata(\"CPSSW9204\")\n\nset.seed(123)\n\nData <- recipe(earnings~ year + degree + gender + age,\n            CPSSW9204) |> \n  step_dummy(all_nominal_predictors()) |> \n  prep() |> \n  bake(CPSSW9204)\n```\n:::\n\n\n## 推定\n\n### 推定タスクの定義\n\n\n::: {.cell}\n\n```{.r .cell-code}\nTask <- as_task_regr(Data, target = \"earnings\")\n```\n:::\n\n\n### 個別推定方法の定義\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMesurementR2 <-  msr(\"regr.rsq\")\n\nResampleCV <- rsmp(\"cv\")\n\nLearnerLASSO <- lrn(\"regr.cv_glmnet\")\n\nLearnerOLS <- lrn(\"regr.lm\")\n\nLearnerRF <- lrn(\"regr.ranger\")\n\nLearnerTree <- lrn(\"regr.rpart\")\n\nLearnerTree$param_set$values$cp = 0\nLearnerTree$param_set$values$minsplit = 17\n```\n:::\n\n\n#### SuperLearnerの定義\n\n\n::: {.cell}\n\n```{.r .cell-code}\nBaseLearner <- list(\n  LearnerOLS,\n  LearnerLASSO,\n  LearnerRF,\n  LearnerTree\n) # 個別推定アルゴリズム\n\nSuperLearner <- lrn(\"regr.lm\",\n                    id = \"SuperLearner\") # 個別予測をまとめるアルゴリズム\n\nLearnerStack <- pipeline_stacking(BaseLearner, SuperLearner) |> \n  as_learner()\n```\n:::\n\n\n\n\n### 交差推定\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlgr::get_logger(\"mlr3\")$set_threshold(\"warn\")\n\nFitOLS <- resample(Task, LearnerOLS, ResampleCV, store_models = TRUE)\nFitLASSO <- resample(Task, LearnerLASSO, ResampleCV, store_models = TRUE)\nFitRF <- resample(Task, LearnerRF, ResampleCV, store_models = TRUE)\nFitStack <- resample(Task, LearnerStack, ResampleCV, store_models = TRUE)\n```\n:::\n\n\n### ベンチマーク・テスト\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndesign <- benchmark_grid(\n  tasks = Task,\n  learners = list(LearnerOLS,\n                  LearnerLASSO,\n                  LearnerRF,\n                  LearnerTree,\n                  LearnerStack),\n  resamplings = ResampleCV\n)\n\nBenchMark <- benchmark(design)\n\nBenchMark$aggregate(MesurementR2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   nr      resample_result task_id\n1:  1 <ResampleResult[21]>    Data\n2:  2 <ResampleResult[21]>    Data\n3:  3 <ResampleResult[21]>    Data\n4:  4 <ResampleResult[21]>    Data\n5:  5 <ResampleResult[21]>    Data\n                                                                    learner_id\n1:                                                                     regr.lm\n2:                                                              regr.cv_glmnet\n3:                                                                 regr.ranger\n4:                                                                  regr.rpart\n5: regr.lm.regr.cv_glmnet.regr.ranger.regr.rpart.nop.featureunion.SuperLearner\n   resampling_id iters  regr.rsq\n1:            cv    10 0.2700908\n2:            cv    10 0.2562989\n3:            cv    10 0.2772767\n4:            cv    10 0.2789252\n5:            cv    10 0.2807332\n```\n:::\n:::\n\n::: {.cell}\n\n:::\n",
    "supporting": [
      "Prediction_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}