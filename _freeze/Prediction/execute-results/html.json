{
  "hash": "5547ad11f4ed7ecc5dfdef75e41e139e",
  "result": {
    "markdown": "# 教師付き学習による母平均モデルの推定 {#sec-Prediction}\n\n- 手持ちのデータと同じ母集団から新しくランダムサンプリングされ、$X$のみが観察できるサンプルについて$Y$の値を予測する。\n\n  - データ分割を用いたモデル選択、評価を行う\n\n## 問題設定\n\n- 事前に定義する損失関数の母平均 (Population Risk) を最小化するような、予測関数$f(X)$の推定を目指す。\n\n  - 以下ではMean squared error(MSE)を損失関数として用いる。確率変数$Y,X$について予測問題は以下のように定義できる\n\n$$\\min_{f(X)}MSE = \\int_{x}E[(Y_i-f(x))^2|X_i=x]\\times g(x)dx$$\n\n- $g(x)$ は$x$の分布関数\n\n  - 一般に以下の最適化問題の解と一致\n\n$$\\min_{f(X_i)} \\int_{x}E[(\\mu(x)-f(x))^2|X_i=x]g(x)dx$$\n\nただし $\\mu(x)=E[Y_i|X_i=x]$\n\n    - 理想の予測モデルは、 $Y$ の条件付き母平均 (母平均関数)\n    \n    - 母平均関数を上手く近似する関数 $f(X)$ の推定を目指す\n\n- 上記問題を具体的に解くアルゴリズムとして、ここでは OLS, LASSO, Random Forest、およびそれらのSuperLearnerを実装する。\n\n## 実装\n\n::: {.panel-tabset}\n\n### R\n\n- 以下のPipelineを実装\n\n\n```{mermaid}\nflowchart TB\n  A[データとパッケージの読み込み] --> B[予測タスクの定義/サンプル分割]\n  B --> C1[BuildIn 推定アルゴリズムの定義]\n  B --> C2[+ 前処理]\n  B --> C3[+ パラメータTuning]\n  C1 --> C4[Super Learnerの定義]\n  C2 --> C4[Super Learnerの定義]\n  C3 --> C4[Super Learnerの定義]\n  C1 --> D[Trainデータのみを用いたベンチマーク]\n  C2 --> D[Trainデータのみを用いたベンチマーク]\n  C3 --> D[Trainデータのみを用いたベンチマーク]\n  C4 --> D[Trainデータのみを用いたベンチマーク]\n  D --> E[最善の予測モデルを用いた最終推計]\n  E --> F[Testデータによる評価]\n```\n\n\n\n#### パッケージ & データ\n\n- ここではpipelinesによるデータ整備は行わない (暫定的)\n\n- 追加でlgr (表示するメッセージを操作), future (並列計算)  パッケージを使用\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(mlr3verse) # <1>\nlibrary(mlr3pipelines) # <2>\n\nRaw <- read_csv(\"ExampleData/Example.csv\")\n\nset.seed(123)\n```\n:::\n\n\n1. 教師付き学習のメタパッケージ\n\n2. Stacking用\n\n#### 推定タスクの定義\n\n- 分割数、繰り返し計算回数は最小限に設定\n\n    - 実戦では増やす\n\n\n::: {.cell}\n\n```{.r .cell-code}\nTask <- as_task_regr(\n  Raw, \n  target = \"Price\",\n  id = \"Price\") # <1>\n\nR2 <-  msr(\"regr.rsq\") # <2>\n\nCV <- rsmp(\"cv\",folds = 2) # <3>\n\nTerminal = trm(\n  \"evals\",\n  n_evals = 20) # <4>\n\nTuner <- tnr(\"random_search\") # <5>\n```\n:::\n\n\n1. 推定に用いるデータと結果変数を指定\n\n2. R2を評価指標に使用\n\n3. 2分割交差検証を指定\n\n4. 20個のパラメタセットを検証\n\n5. ランダムサーチで検証するパラメタセットを選ぶ\n\n#### 使用するBuildIn Algorithmを定義\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSimpleOLS <- lrn( # <1>\n  \"regr.lm\", # <1>\n  id = \"SimpleOLS\" # <1>\n  ) # <1>\n\nRandomForest <- lrn( # <2>\n  \"regr.ranger\", # <2>\n  id = \"RandomForest\" # <2>\n  ) # <2>\n```\n:::\n\n\n1. 単純なOLS\n\n2. RandomForest\n\n#### PreProcess\n\n- 線形モデルについて、連続変数二乗項と交差項を導入\n\n    - [Duflo](https://github.com/demirermert/MLInference/blob/master/NBER_SI_DEV_master_lecture.pdf) のおすすめ\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMutate = po(\"mutate\") # <1>\n\nMutate$param_set$values$mutation = list( # <2>\n  Size2 = ~ Size*Size, # <2>\n  TradeQ2 = ~ TradeQ*TradeQ, # <2>\n  BuildYear2 = ~BuildYear*BuildYear, # <2>\n  Distance2 = ~Distance*Distance, # <2>\n  Size_TradeQ = ~Size*TradeQ, # <2>\n  Size_BuildYear = ~Size*BuildYear, # <2>\n  Size_Distance = ~ Size*Distance, # <2>\n  TradeQ_BuildYear = ~TradeQ*BuildYear, # <2>\n  TradeQ_Distance = ~TradeQ*Distance, # <2>\n  BuildYear_Distance = ~BuildYear*Distance # <2>\n  )  # <2>\n\nScale = po(\"scale\") # <3>\n\nOLS <- Mutate %>>% # <4>\n  Scale %>>% # <4>\n  lrn(\"regr.lm\") |> # <4>\n  as_learner() # <4>\n\nOLS$id <- \"OLS\" # <4>\n```\n:::\n\n\n1. $X$ の加工\n\n2. 二乗項と交差項を作成\n\n3. 標準化(平均を引き、標準偏差で叙す)\n\n4. OLSと結合\n\n#### チューニング付き推定方法の定義\n\n- Tree、ElasticNet (LASSO/Ridge) アルゴリズムについて、HyperParameterを交差検証により推定する\n\n- 探索するHyperParameterの範囲を設定する必要がある\n\n    - [mlr3tuningspaces](https://github.com/mlr-org/mlr3tuningspaces)パッケージが提供するおすすめ範囲を使用\n\n\n::: {.cell}\n\n```{.r .cell-code}\nTree <- lrn(\"regr.rpart\") |> \n  lts() # <1>\n\nTree <- AutoTuner$new( # <2>\n  learner = Tree, # <2>\n  resampling = CV, # <2>\n  measure = R2, # <2>\n  terminator = Terminal, # <2>\n  tuner = Tuner # <2>\n  ) # <2>\n\nTree$id <- \"Tree\" # <3>\n\nRegulizedLinear <- lrn(\"regr.glmnet\") |> \n  lts() # <4>\n\nRegulizedLinear <- Mutate %>>% \n  Scale %>>% \n  RegulizedLinear |> \n  as_learner() # <5>\n\nRegulizedLinear <- AutoTuner$new( # <6>\n  learner = RegulizedLinear, # <6>\n  resampling = CV, # <6>\n  measure = R2, # <6>\n  terminator = Terminal, # <6>\n  tuner = Tuner # <6>\n  ) # <6>\n\nRegulizedLinear$id <- \"ElasticNet\" # <7>\n```\n:::\n\n\n1. TuningSpaceを指定したTreeを定義\n\n2. HyperParameter Tuningを指定\n\n3. Treeと名づける\n\n4. TuningSpaceを指定したElasticNetを定義\n\n5. 二乗項/交差項作成を付与\n\n6. HyperParameter Tuningを指定\n\n7. ElasticNetと名づける\n\n#### SuperLearnerの定義\n\n\n::: {.cell}\n\n```{.r .cell-code}\nBaseLearner <- list( # <1>\n  OLS, # <1>\n  RandomForest, # <1>\n  Tree, # <1>\n  RegulizedLinear # <1>\n  ) # <1>\n\nSuperLearner <- lrn( # <2>\n  \"regr.lm\", # <2>\n  id = \"SuperLearner\") # <2>\n\nStacking <- pipeline_stacking( # <3>\n  BaseLearner,  # <3>\n  SuperLearner, # <3>\n  use_features = FALSE) |>  # <3>\n  as_learner() # <3>\n\nStacking$id <- \"Stacking\" # <4>\n```\n:::\n\n\n1. 個別のアルゴリズムの指定\n\n2. 集計用アルゴリズムの指定\n\n3. Stackingの定義\n\n4. Stackingと名づけ\n\n#### 交差推定による評価\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDesign <- benchmark_grid( # <1>\n  tasks = Task, # <2>\n  learners = list( # <3>\n    OLS, # <3>\n    SimpleOLS, # <3>\n    RegulizedLinear, # <3>\n    RandomForest, # <3>\n    Tree, # <3>\n    Stacking # <3>\n  ), # <3>\n  resamplings = CV # <4>\n  )\n\nlgr::get_logger(\"mlr3\")$set_threshold(\"error\") # <5>\nlgr::get_logger(\"bbotk\")$set_threshold(\"error\") # <5>\nfuture::plan(\"multisession\") # <6>\n\nBenchMark <- benchmark(Design) # <7>\n\nBenchMark$aggregate(R2) # <8>\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   nr task_id   learner_id resampling_id iters  regr.rsq\n1:  1   Price          OLS            cv     2 0.4806426\n2:  2   Price    SimpleOLS            cv     2 0.4372492\n3:  3   Price   ElasticNet            cv     2 0.4574927\n4:  4   Price RandomForest            cv     2 0.5012793\n5:  5   Price         Tree            cv     2 0.4668550\n6:  6   Price     Stacking            cv     2 0.5078875\nHidden columns: resample_result\n```\n:::\n:::\n\n\n1. 評価の枠組みを定義\n\n2. 評価対象のタスク (データと結果変数) を定義\n\n3. 評価対象のアルゴリズムを定義\n\n4. 評価方法 (交差検証) を定義\n\n5. Errorメッセージのみ表示\n\n6. 並列処理を指定\n\n7. 評価を実行\n\n8. R2を計算\n\n- RandomForestとStackingはComparableな性能\n\n\n### Python\n\n- OLSとRandom Forestで予測モデルを推定し、交差検証で比較する。\n\n#### パッケージ & データ\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom sklearn import linear_model\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nimport pandas as pd\nimport numpy as np\n\ndata = pd.read_csv(\"ExampleData/Example.csv\")\n\nnp.random.seed(123) # Fix seed\n\nY = data['Price']\n\nX = data.drop(\n  'Price',\n  axis = 1)\n```\n:::\n\n\n#### 使用するアルゴリズム\n\n\n::: {.cell}\n\n```{.python .cell-code}\nOLS = linear_model.LinearRegression() # OLS\n\nRF = RandomForestRegressor(\n  n_estimators = 500) # Random Forest\n```\n:::\n\n\n#### 交差推定によるテスト\n\n\n::: {.cell}\n\n```{.python .cell-code}\nFolds = KFold(n_splits=5, shuffle = True) # サンプル5分割\n```\n:::\n\n\n- OLS のテスト\n\n\n::: {.cell}\n\n```{.python .cell-code}\nnp.mean(cross_val_score(OLS, X, Y, cv = Folds))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.45701534421807366\n```\n:::\n:::\n\n\n- Random Forestのテスト\n\n\n::: {.cell}\n\n```{.python .cell-code}\nnp.mean(cross_val_score(RF, X, Y, cv = Folds))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.5162822824693902\n```\n:::\n:::\n\n\n\n:::",
    "supporting": [
      "Prediction_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}