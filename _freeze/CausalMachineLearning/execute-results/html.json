{
  "hash": "f5db8ebbe4301c81a56519bdef49a6ae",
  "result": {
    "markdown": "# セミパラメトリック推定によるパラメタ推定 {#sec-CausalMachine}\n\n-   @chernozhukov2018 を実装する\n\n## 設定\n\n::: {.panel-tabset}\n\n### R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(recipes)\nlibrary(mlr3verse)\nlibrary(mlr3pipelines)\nlibrary(data.table)\nlibrary(DoubleML)\n\nData_R <- fread(\"ExampleData/Example.csv\")\n\nTask_R <- double_ml_data_from_data_frame(Data_R,\n                                         x_cols = c(\"TradeQ\", \"Size\", \"BuildYear\", \"Distance\"),\n                                         y_col = c(\"Price\"),\n                                         d_cols = c(\"Reform\"))\n```\n:::\n\n\n### Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\nfrom sklearn.base import clone\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import RandomForestClassifier\nfrom doubleml import DoubleMLData\nfrom doubleml import DoubleMLPLR\nfrom doubleml import DoubleMLIRM\n\nData_Python = pd.read_csv('ExampleData/Example.csv')\n\nTask_Python = DoubleMLData(Data_Python, \n                          y_col = 'Price',\n                          d_cols = 'Reform',\n                          x_cols = ['TradeQ',\"Size\",\"Distance\",\"BuildYear\"])\n```\n:::\n\n\n\n:::\n\n## 平均効果の推定: Partial Linear Model\n\n- 部分線形モデル [@robinson1988]\n\n- RandomForestとOLSのStackingを用いる\n\n    - Pythonについて、現状、RandomForestのみ\n\n::: {.panel-tabset}\n\n### R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nRegOLS <- lrn(\"regr.lm\",\n  id = \"RegressionOLS\"\n)\n\nRegRF <- lrn(\"regr.ranger\",\n  id = \"RegressionRandomForest\"\n)\n\nRegLearners <- list(\n  RegOLS,\n  RegRF\n)\n\nRegSuperLearner <- lrn(\"regr.lm\",\n                    id = \"RegressionSuperLearner\")\n\nRegNuisanceLearner <- \n  pipeline_stacking(RegLearners, RegSuperLearner) |> \n  as_learner()\n\nlgr::get_logger(\"mlr3\")$set_threshold(\"warn\")\n\nFitPLR_R <- DoubleMLPLR$new(Task_R,\n                            ml_l=RegNuisanceLearner$clone(), \n                            ml_m=RegNuisanceLearner$clone(),\n                            n_folds = 2)\n\nFitPLR_R$fit()\n\nprint(FitPLR_R)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n================= DoubleMLPLR Object ==================\n\n\n------------------ Data summary      ------------------\nOutcome variable: Price\nTreatment variable(s): Reform\nCovariates: TradeQ, Size, BuildYear, Distance\nInstrument(s): \nNo. Observations: 14793\n\n------------------ Score & algorithm ------------------\nScore function: partialling out\nDML algorithm: dml2\n\n------------------ Machine learner   ------------------\nml_l: RegressionOLS.RegressionRandomForest.nop.featureunion.RegressionSuperLearner\nml_m: RegressionOLS.RegressionRandomForest.nop.featureunion.RegressionSuperLearner\n\n------------------ Resampling        ------------------\nNo. folds: 2\nNo. repeated sample splits: 1\nApply cross-fitting: TRUE\n\n------------------ Fit summary       ------------------\n Estimates and significance testing of the effect of target variables\n       Estimate. Std. Error t value Pr(>|t|)    \nReform    4.8926     0.4061   12.05   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n### Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nFitPLR_Python = DoubleMLPLR(Task_Python,\n                            RandomForestRegressor(n_estimators = 500),\n                            RandomForestRegressor(n_estimators = 500),\n                            n_folds = 2)\n\nFitPLR_Python.fit()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<doubleml.double_ml_plr.DoubleMLPLR object at 0x298446340>\n```\n:::\n\n```{.python .cell-code}\nprint(FitPLR_Python)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n================== DoubleMLPLR Object ==================\n\n------------------ Data summary      ------------------\nOutcome variable: Price\nTreatment variable(s): ['Reform']\nCovariates: ['TradeQ', 'Size', 'Distance', 'BuildYear']\nInstrument variable(s): None\nNo. Observations: 14793\n\n------------------ Score & algorithm ------------------\nScore function: partialling out\nDML algorithm: dml2\n\n------------------ Machine learner   ------------------\nLearner ml_l: RandomForestRegressor(n_estimators=500)\nLearner ml_m: RandomForestRegressor(n_estimators=500)\n\n------------------ Resampling        ------------------\nNo. folds: 2\nNo. repeated sample splits: 1\nApply cross-fitting: True\n\n------------------ Fit summary       ------------------\n            coef   std err          t         P>|t|     2.5 %   97.5 %\nReform  5.224552  0.361128  14.467301  1.949731e-47  4.516753  5.93235\n```\n:::\n:::\n\n\n:::\n\n## 平均効果の推定: AIPW\n\n-   AIPW [@robins1995]\n\n::: {.panel-tabset}\n\n### R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nProbOLS <- lrn(\"classif.log_reg\",\n  id = \"ProbLM\",\n  predict_type = \"prob\"\n)\n\nProbRF <- lrn(\"classif.ranger\",\n  id = \"ProbRanger\",\n  predict_type = \"prob\"\n)\n\nProbLearners <- list(ProbOLS,ProbRF)\n\nProbSuperLearner <- lrn(\"classif.log_reg\",\n                    id = \"ProbSuperLearner\")\n\nProbNuisanceLearner <- pipeline_stacking(ProbLearners, ProbSuperLearner) |> \n  as_learner()\n\nlgr::get_logger(\"mlr3\")$set_threshold(\"warn\")\n\nFitAIPW_R = DoubleMLIRM$new(Task_R,\n                            ml_g=RegNuisanceLearner, \n                            ml_m=ProbNuisanceLearner,\n                            n_folds = 2,\n                            trimming_threshold = 0.1)\n\nFitAIPW_R$fit()\n\nprint(FitAIPW_R)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n================= DoubleMLIRM Object ==================\n\n\n------------------ Data summary      ------------------\nOutcome variable: Price\nTreatment variable(s): Reform\nCovariates: TradeQ, Size, BuildYear, Distance\nInstrument(s): \nNo. Observations: 14793\n\n------------------ Score & algorithm ------------------\nScore function: ATE\nDML algorithm: dml2\n\n------------------ Machine learner   ------------------\nml_g: RegressionOLS.RegressionRandomForest.nop.featureunion.RegressionSuperLearner\nml_m: ProbLM.ProbRanger.nop.featureunion.ProbSuperLearner\n\n------------------ Resampling        ------------------\nNo. folds: 2\nNo. repeated sample splits: 1\nApply cross-fitting: TRUE\n\n------------------ Fit summary       ------------------\n Estimates and significance testing of the effect of target variables\n       Estimate. Std. Error t value Pr(>|t|)    \nReform    3.8588     0.4247   9.086   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n### Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nFitAIPW_Python = DoubleMLIRM(Task_Python,\n                            RandomForestRegressor(n_estimators = 500),\n                            RandomForestClassifier(n_estimators = 500),\n                            n_folds = 2,\n                            trimming_threshold = 0.1)\n  \nFitAIPW_Python.fit()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<doubleml.double_ml_irm.DoubleMLIRM object at 0x16ba7f430>\n```\n:::\n\n```{.python .cell-code}\nFitAIPW_Python.summary\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            coef   std err         t         P>|t|     2.5 %    97.5 %\nReform  4.348929  0.545113  7.978028  1.486896e-15  3.280526  5.417331\n```\n:::\n:::\n\n\n:::\n",
    "supporting": [
      "CausalMachineLearning_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}