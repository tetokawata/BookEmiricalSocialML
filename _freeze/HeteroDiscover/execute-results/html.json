{
  "hash": "d6691747edabd455d3436fc24b6513f2",
  "result": {
    "markdown": "# 異質性の探索 {#sec-HeteroDiscover}\n\n- 条件付き平均差 $\\tau(X)=E[Y|D=1,X]-E[Y|D=0,X]$の(ノンパラメトリックな)推定値を異質性のシグナルとして活用\n\n    - 一般に、条件付きの平均差のノンパラメトリックな推定値について、推定誤差を評価するのが難しいため\n    \n    - 効果の異質性の\"シグナル\"として使う [@chernozhukov2018generic; @kallus2022treatment]\n    \n    - $E[\\tau(X)|\\tau(X)\\le Median(\\tau(X))]$ を推定\n\n- $\\tau(X)$ はCausal Forest [@wager2018estimation;@athey2019generalized] で推定\n\n## 設定\n\n::: {.panel-tabset}\n\n### R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(grf)\nlibrary(DoubleML)\nlibrary(mlr3verse)\n\nData_R <- read_csv(\"ExampleData/Example.csv\")\n\nGroup <- sample(0:1,nrow(Data_R),replace = TRUE)\n\nY <- Data_R$Price\n\nD <- Data_R$Reform\n\nX <- Data_R |> \n  select(\n    -Price,\n    -Reform\n  )\n```\n:::\n\n\n- [grf](https://github.com/grf-labs/grf)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nEstCF <- causal_forest(\n  X = X[Group == 0,],\n  W = D[Group == 0],\n  Y = Y[Group == 0]\n)\n\nPredTau <- EstCF |> \n  predict(X)\n\nhist(PredTau$predictions)\n```\n\n::: {.cell-output-display}\n![](HeteroDiscover_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nTask <- double_ml_data_from_matrix(\n  X = X[Group == 1,],\n  y = Y[Group == 1],\n  d = D[Group == 1]\n)\n\nEstDML <- DoubleMLPLR$new(\n  Task,\n  lrn(\"regr.lm\"),\n  lrn(\"regr.lm\")\n)\n\nEstDML$fit()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nINFO  [21:02:33.207] [mlr3] Applying learner 'regr.lm' on task 'nuis_l' (iter 1/5)\nINFO  [21:02:33.229] [mlr3] Applying learner 'regr.lm' on task 'nuis_l' (iter 2/5)\nINFO  [21:02:33.239] [mlr3] Applying learner 'regr.lm' on task 'nuis_l' (iter 3/5)\nINFO  [21:02:33.246] [mlr3] Applying learner 'regr.lm' on task 'nuis_l' (iter 4/5)\nINFO  [21:02:33.253] [mlr3] Applying learner 'regr.lm' on task 'nuis_l' (iter 5/5)\nINFO  [21:02:33.334] [mlr3] Applying learner 'regr.lm' on task 'nuis_m' (iter 1/5)\nINFO  [21:02:33.515] [mlr3] Applying learner 'regr.lm' on task 'nuis_m' (iter 2/5)\nINFO  [21:02:33.522] [mlr3] Applying learner 'regr.lm' on task 'nuis_m' (iter 3/5)\nINFO  [21:02:33.528] [mlr3] Applying learner 'regr.lm' on task 'nuis_m' (iter 4/5)\nINFO  [21:02:33.534] [mlr3] Applying learner 'regr.lm' on task 'nuis_m' (iter 5/5)\n```\n:::\n\n```{.r .cell-code}\nEstDML\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n================= DoubleMLPLR Object ==================\n\n\n------------------ Data summary      ------------------\nOutcome variable: y\nTreatment variable(s): d\nCovariates: X1, X2, X3, X4\nInstrument(s): \nNo. Observations: 7375\n\n------------------ Score & algorithm ------------------\nScore function: partialling out\nDML algorithm: dml2\n\n------------------ Machine learner   ------------------\nml_l: regr.lm\nml_m: regr.lm\n\n------------------ Resampling        ------------------\nNo. folds: 5\nNo. repeated sample splits: 1\nApply cross-fitting: TRUE\n\n------------------ Fit summary       ------------------\n Estimates and significance testing of the effect of target variables\n  Estimate. Std. Error t value Pr(>|t|)    \nd    3.2798     0.5999   5.468 4.56e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nQ <- quantile(PredTau$predictions,0.5)\n\nTask <- double_ml_data_from_matrix(\n  X = X[Group == 1 & PredTau$predictions >= Q,],\n  y = Y[Group == 1 & PredTau$predictions >= Q],\n  d = D[Group == 1 & PredTau$predictions >= Q]\n)\n\nEstDML <- DoubleMLPLR$new(\n  Task,\n  lrn(\"regr.lm\"),\n  lrn(\"regr.lm\")\n)\n\nEstDML$fit()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nINFO  [21:02:33.617] [mlr3] Applying learner 'regr.lm' on task 'nuis_l' (iter 1/5)\nINFO  [21:02:33.624] [mlr3] Applying learner 'regr.lm' on task 'nuis_l' (iter 2/5)\nINFO  [21:02:33.630] [mlr3] Applying learner 'regr.lm' on task 'nuis_l' (iter 3/5)\nINFO  [21:02:33.637] [mlr3] Applying learner 'regr.lm' on task 'nuis_l' (iter 4/5)\nINFO  [21:02:33.643] [mlr3] Applying learner 'regr.lm' on task 'nuis_l' (iter 5/5)\nINFO  [21:02:33.687] [mlr3] Applying learner 'regr.lm' on task 'nuis_m' (iter 1/5)\nINFO  [21:02:33.693] [mlr3] Applying learner 'regr.lm' on task 'nuis_m' (iter 2/5)\nINFO  [21:02:33.698] [mlr3] Applying learner 'regr.lm' on task 'nuis_m' (iter 3/5)\nINFO  [21:02:33.704] [mlr3] Applying learner 'regr.lm' on task 'nuis_m' (iter 4/5)\nINFO  [21:02:33.710] [mlr3] Applying learner 'regr.lm' on task 'nuis_m' (iter 5/5)\n```\n:::\n\n```{.r .cell-code}\nEstDML\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n================= DoubleMLPLR Object ==================\n\n\n------------------ Data summary      ------------------\nOutcome variable: y\nTreatment variable(s): d\nCovariates: X1, X2, X3, X4\nInstrument(s): \nNo. Observations: 3678\n\n------------------ Score & algorithm ------------------\nScore function: partialling out\nDML algorithm: dml2\n\n------------------ Machine learner   ------------------\nml_l: regr.lm\nml_m: regr.lm\n\n------------------ Resampling        ------------------\nNo. folds: 5\nNo. repeated sample splits: 1\nApply cross-fitting: TRUE\n\n------------------ Fit summary       ------------------\n Estimates and significance testing of the effect of target variables\n  Estimate. Std. Error t value Pr(>|t|)    \nd    5.3312     0.8785   6.069 1.29e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n\n### Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\nimport sklearn.model_selection  as model_selection\n\nData_Python = pd.read_csv('ExampleData/Example.csv')\n\ny = Data_Python['Price']\n\nd = Data_Python['Reform']\n\nx = Data_Python.drop(['Price','Reform'],axis=1).values\n\ny_train, y_test,d_train,d_test,x_train,x_test = model_selection.train_test_split(\n  y,\n  d,\n  x,\n  train_size = 0.5\n  )\n```\n:::\n\n\n- [econml](https://econml.azurewebsites.net/)\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport econml.dml as dml\nimport sklearn.linear_model as Linear\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nest_cf = dml.CausalForestDML(\n    model_y = Linear.LinearRegression(),\n    model_t = Linear.LinearRegression(),\n    n_estimators=2000\n)\n\nest_cf = est_cf.fit(y_train, d_train, X = x_train, W=None)\n\npred_tau = est_cf.effect(x_test)\n\nfig = plt.figure()\n\nsns.histplot(pred_tau)\n```\n\n::: {.cell-output-display}\n![](HeteroDiscover_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nimport doubleml as DML\n\nTask = DML.DoubleMLData.from_arrays(x_test, y_test, d_test)\n                    \nFitPLR = DML.DoubleMLPLR(\n  Task,\n   Linear.LinearRegression(),\n   Linear.LinearRegression(),\n  n_folds = 2\n  )\n\nFitPLR.fit(store_predictions = True)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    ================== DoubleMLPLR Object ==================    \n                                                                \n    ------------------ Data summary      ------------------     \n                      Outcome variable: y                       \n                  Treatment variable(s): ['d']                  \n              Covariates: ['X1', 'X2', 'X3', 'X4']              \n                  Instrument variable(s): None                  \n                     No. Observations: 7397                     \n                                                                \n    ------------------ Score & algorithm ------------------     \n                Score function: partialling out                 \n                      DML algorithm: dml2                       \n                                                                \n    ------------------ Machine learner   ------------------     \n                Learner ml_l: LinearRegression()                \n                Learner ml_m: LinearRegression()                \n                                                                \n    ------------------ Resampling        ------------------     \n                          No. folds: 2                          \n                 No. repeated sample splits: 1                  \n                   Apply cross-fitting: True                    \n                                                                \n    ------------------ Fit summary       ------------------     \n       coef   std err        t         P>|t|     2.5 %    97.5 %\nd  3.580131  0.562229  6.36774  1.918334e-10  2.478182  4.682081\n```\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nimport numpy as np\n\nQ = np.quantile(a=pred_tau, q=0.5)\n\nTask = DML.DoubleMLData.from_arrays(x_test[pred_tau >= Q], y_test[pred_tau >= Q], d_test[pred_tau >= Q])\n                    \nFitPLR = DML.DoubleMLPLR(\n  Task,\n   Linear.LinearRegression(),\n   Linear.LinearRegression(),\n  n_folds = 2\n  )\n\nFitPLR.fit(store_predictions = True)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     ================== DoubleMLPLR Object ==================    \n                                                                 \n     ------------------ Data summary      ------------------     \n                       Outcome variable: y                       \n                   Treatment variable(s): ['d']                  \n               Covariates: ['X1', 'X2', 'X3', 'X4']              \n                   Instrument variable(s): None                  \n                      No. Observations: 3699                     \n                                                                 \n     ------------------ Score & algorithm ------------------     \n                 Score function: partialling out                 \n                       DML algorithm: dml2                       \n                                                                 \n     ------------------ Machine learner   ------------------     \n                 Learner ml_l: LinearRegression()                \n                 Learner ml_m: LinearRegression()                \n                                                                 \n     ------------------ Resampling        ------------------     \n                           No. folds: 2                          \n                  No. repeated sample splits: 1                  \n                    Apply cross-fitting: True                    \n                                                                 \n     ------------------ Fit summary       ------------------     \n       coef   std err         t         P>|t|     2.5 %    97.5 %\nd  4.153337  0.774872  5.360028  8.320895e-08  2.634615  5.672059\n```\n:::\n:::\n\n\n\n:::",
    "supporting": [
      "HeteroDiscover_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}